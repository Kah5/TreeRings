---
title: "KF_tree_rings"
author: "Kelly Heilman"
date: "February 8, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Kalman Filter/Time varying Regression model to estimate tree ring regressions 
code  based off an example from:
<http://lalas.github.io/quantitativeThoughts/r/2014/09/01/dlmTutorial.html#topic2.1>
```{r cars}
library(dplR)
Bonanza <- read.tucson("./cofecha/BONww.rwl", header = TRUE)
BON.rwi <- detrend(rwl = Bonanza, method = "Spline")
plot(BON.rwi)
#create chronology of sites
BON.crn <- chron(BON.rwi, prefix = paste('BON'))
plot(BON.crn)

head(BON.crn)

# read in molten df with climate
molten.HIC<- read.csv('data/molten.hic.csv')

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
library(PerformanceAnalytics, quietly = TRUE,  warn.conflicts = FALSE)
library(dlm)

val <- molten.BON
clim <- "Jul.pdsi"
kalman.plot <- function(val, clim){
# convert to xts objects
tr<- as.xts(val[,c("value")], order.by = as.yearqtr(val$Year))
pdsi <- as.xts(val[,c( clim )], order.by = as.yearqtr(val$Year))

# Specifying a set model parameters
s2_obs = 1      # Variance of observations
s2_alpha = 0.01 # Variance of the alpha regression parameter
s2_beta = 0.01  # Variance of the beta regression parameter

# Construct a regression model
tvp.dlm = dlmModReg(X=pdsi, addInt=TRUE, dV=s2_obs, dW=c(s2_alpha, s2_beta))

#Now that we have define a model, we can view its different component:

# looking at the various component
tvp.dlm[c("FF","V","GG","W","m0","C0")]
tvp.dlm[c("JFF","JV","JGG","JW")]

#If we were to do a simple linear regression (Ordinary Least Square fit - constant equity beta), we would do something like

#ols.fit = lm(HAM1 ~ sp500)
ols.fit <- lm(tr ~ pdsi)
summary(ols.fit)

start.vals = c(0,0,0)
# Names ln variance of: observation y, alpha and beta (corresponding intercept and slope of y (tr index) with respect to X (PDSI))
names(start.vals) = c("lns2_obs", "lns2_alpha", "lns2_beta")

# function to build Time Varying Parameter state space model
buildTVP <- function(parm, x.mat){
    parm <- exp(parm)
  return( dlmModReg(X=x.mat, dV=parm[1], dW=c(parm[2], parm[3])) )
}

# Estimate the model
TVP.mle = dlmMLE(y=tr, parm=start.vals, x.mat=pdsi, build=buildTVP, hessian=T)

# get sd estimates
se2 <- sqrt(exp(TVP.mle$par))
names(se2) = c("s_obs", "s_alpha", "s_beta")
sqrt(se2)


# Build fitted ss model, passing to it sp500 as the matrix X in the model
TVP.dlm <- buildTVP(TVP.mle$par, pdsi)
#Filtering and Smooting:
#Filtering Optimal estimates of θtθt given information available at time tt, It={y1,...,yt}It={y1,...,yt}
#Smoothing Optimal estimates of θtθt given information available at time TT, IT={y,...,yT}IT={y,...,yT}
#Now that we have obtained model estimates, and build the optimal model, we can filter the data through it, to obtain filtered values of the state vectors, together with their variance/co-variance matrices.

TVP.f <- dlmFilter(y = tr, mod = TVP.dlm)
#class(TVP.f)

#names(TVP.f)

#Similarly, to obtained the smoothed values of the state vectors, together with their variance/co-variance matrices; using knowledge of the entire series

# Optimal estimates of θ_t given information available at time T.
TVP.s <- dlmSmooth(TVP.f)
#class(TVP.s)



#Plotting the results (smoothed values)
#Now that we have obtained the smoothed values of the state vectors, we can draw them as:



# extract smoothed states - intercept and slope coefs
alpha.s = xts(TVP.s$s[-1,1,drop=FALSE], as.yearqtr( rownames(TVP.s$s[-1,])))

beta.s  = xts(TVP.s$s[-1,2,drop=FALSE], as.yearqtr(rownames(TVP.s$s[-1,])))
colnames(alpha.s) = "alpha"
colnames(beta.s)  = "beta"
#Extracting the std errors and constructing the confidence band

# extract std errors - dlmSvd2var gives list of MSE matrices
mse.list = dlmSvd2var(TVP.s$U.S, TVP.s$D.S)
se.mat = t(sapply(mse.list, FUN=function(x) sqrt(diag(x))))
se.xts = xts(se.mat[-1, ], index(beta.s))
colnames(se.xts) = c("alpha", "beta")
a.u = alpha.s + 1.96*se.xts[, "alpha"]
a.l = alpha.s - 1.96*se.xts[, "alpha"]
b.u = beta.s  + 1.96*se.xts[, "beta"]
b.l = beta.s  - 1.96*se.xts[, "beta"]
#And plotting the results with +/- 2 times the standard deviation
par(mfrow = c(2,1))
# plot smoothed estimates with +/- 2*SE bands
chart.TimeSeries(cbind(alpha.s, a.l, a.u), main="Smoothed estimates of alpha", ylim=c(0,2),
                 colorset=c(1,2,2), lty=c(1,2,2),ylab=expression(alpha),xlab="")

chart.TimeSeries(cbind(beta.s, b.l, b.u), main="Smoothed estimates of beta",
                 colorset=c(1,2,2), lty=c(1,2,2),ylab=expression(beta),xlab="")


}

X11(width = 12)
kalman.plot(val = molten.UNC, clim = "Jul.pdsi")
kalman.plot(val = molten.BON, clim = "Jul.pdsi")
kalman.plot(val = molten.HIC, clim = "Jul.pdsi")
kalman.plot(val = molten.STC, clim = "Jul.pdsi")
kalman.plot(val = molten.TOW, clim = "Jul.pdsi")
kalman.plot(val = molten.COR, clim = "Jul.pdsi")
kalman.plot(val = molten.ENG, clim = "Jul.pdsi")
```

## lets try specifying a model using the package FKF
```{r}
library(FKF)
## Local level model for the treering width data.
## Transition equation:
## alpha[t+1] = alpha[t] + eta[t], eta[t] ~ N(0, HHt)
## Measurement equation:
## y[t] = alpha[t] + eps[t], eps[t] ~ N(0, GGt)
y <- treering
y[c(3, 10)] <- NA # NA values can be handled

## Set constant parameters:
dt <- ct <- matrix(0)
Zt <- Tt <- matrix(1)
a0 <- y[1] # Estimation of the first width
P0 <- matrix(100) # Variance of 'a0'

## Estimate parameters:
fit.fkf <- optim(c(HHt = var(y, na.rm = TRUE) * .5,
GGt = var(y, na.rm = TRUE) * .5),
fn = function(par, ...)
-fkf(HHt = matrix(par[1]), GGt = matrix(par[2]), ...)$logLik,
yt = rbind(y), a0 = a0, P0 = P0, dt = dt, ct = ct,
Zt = Zt, Tt = Tt, check.input = FALSE)

## Filter Nile data with estimated parameters:
fkf.obj <- fkf(a0, P0, dt, ct, Tt, Zt, HHt = matrix(fit.fkf$par[1]),
GGt = matrix(fit.fkf$par[2]), yt = rbind(y))

## Plot the width together with fitted local levels:
plot(y, main = "Treering data")
lines(ts(fkf.obj$att[1, ], start = start(y), frequency = frequency(y)), col = "blue")
legend("top", c("Treering data", "Local level"), col = c("black", "blue"), lty = 1)

## Check the residuals for normality:
plot(fkf.obj, type = "resid.qq")

## Test for autocorrelation:
plot(fkf.obj, type = "acf", na.action = na.pass)

```

