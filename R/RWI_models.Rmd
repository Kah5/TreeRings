---
title: "BAI_models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rjags)
library(ggplot2)
library(caTools)

# some initial data checking:
full.ghcn <- read.csv("outputs/data/rwi_age_dbh_ghcn.df")
BAI <- full.ghcn$RWI
hist(BAI)
logBAI<- hist(log(BAI)) # approximates normal when log transformed

```

## Initial bayesian linear regression of climate on Basal Area Index
# this model assumes all trees across all species + sites + forest types have the same relationship with PDSI

```{r}



summary(full.ghcn)
# get all records that have all RWI and don't have negative diams or NA diams
full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH > 0 & !is.na(full.ghcn$DBH),]
Y <- as.vector(log(full.ghcn$RWI)) 
#Y     <- 100*dat[,2]
#Y     <- (Y-mean(Y))/sd(Y)

# standardise predictor variables to have mean 0 and sd = 1
DI.scaled = scale(full.ghcn$JJA.pdsi, center= TRUE, scale=TRUE)
DBH.scaled = scale(full.ghcn$DBH, center= TRUE, scale=TRUE)
full.ghcn$T.scaled = as.vector(scale(full.ghcn$JUNTmax, center= TRUE, scale=TRUE))
full.ghcn$DI.scaled = as.vector(scale(full.ghcn$JJA.pdsi, center = TRUE, scale = TRUE))
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))

#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode

mgcv::gam(data = full.ghcn, RWI ~ DBH.scaled + DI.scaled)


# population model for the response of each BAI to each year of climate:
population_model <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1 +  beta2*DI.scaled[i] + beta3*DBH.scaled[i] +  beta4*T.scaled[i]



}

# Assume normal priors for betas (because they could be negative or positive)

beta1 ~ dnorm(0, 0.001)
beta2 ~ dnorm(0, 0.001)
beta3 ~ dnorm(0,0.001)
beta4 ~ dnorm(0,0.001)


# Non-informative Prior for the inverse variances
inv.var   ~ dgamma(0.01, 0.01)
sigma     <- 1/sqrt(inv.var)


for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1 +  beta2*DI.scaled.p[i] + beta3*DBH.scaled.p[i] + beta4*T.scaled.p[i] # use Drought index


}


}"


sum.lin.reg <- lm(full.ghcn$RWI ~ log(full.ghcn$DI.scaled) + log(full.ghcn$DBH.scaled))
lin.rgr.ests<- summary(sum.lin.reg)$coefficients
# specify initial conditions for the three chains
initsList <- list(
  list(
    # chain 1 has low estimates
    beta1 = lin.rgr.ests[1,1] - 5*lin.rgr.ests[1,2],
    beta2 = lin.rgr.ests[2,1] - 5*lin.rgr.ests[2,2], 
    
    inv.var = 0.0001
  ), 
  # chain 2 has high values
  list(
    beta1 = lin.rgr.ests[1,1] + 5*lin.rgr.ests[1,2],
    beta2 = lin.rgr.ests[2,1] + 5*lin.rgr.ests[2,2], 
    #beta3 = lin.rgr.ests[3,1] + 5*lin.rgr.ests[3,2], 
    inv.var = 1
  ), 
  list(
    # chain 3 has a mix
    beta1 = lin.rgr.ests[1,1] + 5*lin.rgr.ests[1,2],
    beta2 = lin.rgr.ests[2,1] - 5*lin.rgr.ests[2,2], 
    #beta3 = lin.rgr.ests[3,1] + 5*lin.rgr.ests[3,2], 
   inv.var = 100
  )
)

msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]


# now 
reg.model.age <- jags.model(textConnection(population_model), 
                    data = list(Y=log(train$RWI), n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled,T.scaled = train$T.scaled, np = length(test$RWI), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, T.scaled.p = test$T.scaled), n.chains = 3)

update(reg.model.age, 1000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(reg.model.age, 
                     variable.names=c("beta1", "beta2", "beta3", "beta4", "beta5", "sigma", "Yp"), 
                    n.chains = 3, n.iter=2000)



#Extract the samples for each parameter

 samps       <- samp[[1]]
 Yp.samps    <- samps[,1:length(test$X)] 
 alpha.samps <- samps[,(length(test$X)+1)]
 beta.samps  <- samps[,(length(test$X)+2):((length(test$X)+4))]
 sigma.samps <- samps[,(length(test$X)+5)]

 
# caluculate 95% CI for alpha and beta samps 
alpha.025 <- quantile(alpha.samps, 0.025)
alpha.975 <- quantile(alpha.samps, 0.975)
beta1.025 <- quantile(beta.samps[,1], 0.025)
beta1.975 <- quantile(beta.samps[,1], 0.975)
beta2.025 <- quantile(beta.samps[,2], 0.025)
beta2.975 <- quantile(beta.samps[,2], 0.975)



a <- data.frame('alpha' = alpha.samps, 'beta.drought' = beta.samps[,1], 'Beta.dbh' = beta.samps[,2], 'Beta.JunT' = beta.samps[,3])
colnames(a)<- c("alpha", "beta.drought", "beta.dbh", "beta.temp")
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))

# make dot + 95% CI plots for each param
a.mplots <- ggplot(a.m, aes(value, color = variable))+geom_density(alpha = 0.5)+theme_black()

a.m.mean <- apply(as.matrix(a[,1:3]), 2, mean)
a.m.lower <- apply(as.matrix(a[,1:3]), 2, function(x) quantile(x, probs = c(0.025)))
a.m.upper <- apply(as.matrix(a[,1:3]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.a.m <- data.frame(a.m.mean, a.m.lower, a.m.upper)

#plot.dat.a.m$class <- row.names(plot.dat.a.m)

a.m.dots <- ggplot(plot.dat.a.m, aes(x = a.m.mean, y = row.names(plot.dat.a.m)))+geom_errorbarh( xmin = a.m.lower, xmax = a.m.upper,height = 0, size = 2)+geom_point(size = 3)+geom_vline(xintercept = 0, linetype = "dashed")+coord_flip()+theme(legend.position = "none")+xlab("Parameter Estimages")+ylab("Parameters")+theme_bw()+xlim(-0.032, 0.1)

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg/Parameter_estimates.png")
a.m.dots
dev.off()

# plot predicted vs. observed:
## sorted to increase
idx <- order(test[, "RWI"])
pred <- data.frame(Yp.samps)
n_samples <- length(pred[, 1])
X_ci <- apply(pred[, idx], 2, sort)[(0.025*n_samples+1):(0.975*n_samples), ]
sim.df <- data.frame(Covariate=c(X_ci),
                     #Covariate.trans = exp(X_ci),
                     Observation=factor(rep((1:length(test[, "RWI"])),
                                            each=n_samples*0.95)),
                     truth=rep(test[, "RWI"][idx],
                               each=n_samples*0.95))


sim.df$PredRWI <- exp(sim.df$Covariate)

sub <- sample(x = 1:(n_samples*3665), replace = FALSE, size = 100)

png(height=10, width = 14, units = "in",res = 200,"outputs/growth_model/basic_reg/pred_obs_ci.png")
ggplot(na.omit(sim.df[sub,]), aes(truth, PredRWI)) +
  geom_violin(position="identity") +
  geom_point(aes(Observation, truth), color="red") +
  scale_x_discrete(breaks=seq(, 25, 5)) + 
  labs(x="Observed Growth", y="Predicted Growth")
dev.off()

# Compute the posterior mean for the plug-in predictions  

 beta.mn  <- colMeans(beta.samps)
 sigma.mn <- mean(sigma.samps)
 alpha.mn <- mean(alpha.samps) 
 
 plot(colMeans(exp(Yp.samps)), test$RWI)
 abline(a = 0, b = 1, col = "red")

 
  DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.25)
  DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.25)
 
 # something like:
 Xp <- expand.grid(DIprobe, DBHprobe)
 #Xp <- as.matrix(Xp)
# Plot the Posterior Predictive Density and plug-in
np <- length(Xp$Var1)
ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   # Plug-in
   mu <- alpha.mn+sum(Xp[j,]*beta.mn)
   ypred[[j]]  <- rnorm(20000, mu, sigma.mn)
   
    
  
   # Truth
   #abline(v=mean(ypred),col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- data.frame(do.call(rbind, ypred))

Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg/Ypred_by_drought.png")
ggplot(Xp, aes(Var1, MeanY, color = Var2))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg/Ypred_by_DBH.png")
ggplot(Xp, aes(Var2, MeanY))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg/Ypred_by_drought_DBH.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)
dev.off()

#set.seed(13)
m <- 10000
chains <- samp[[1]][,1:4]
chains2 <- samp[[2]][,1:4]

postDraws <- chains[sample(nrow(chains),size=m,replace=TRUE),]



# Sample m draws of y.rep (n obs each) from likelihood p(y|theta), using thetas sampled above. Approximates posterior predictive distribution p(y.rep|y)
n <- nrow(full.ghcn)
y.rep <- matrix(NA, nrow=n, ncol=m)
for (i in 1:m){
  y.rep[,i] <- rnorm(n = n, postDraws[i,"fit"], postDraws[i,"fit.new"])
}

# check to see if the predicted yrep alighs with data y max
T1.y <- max(Y)
T1.yrep <- apply(y.rep, 2, max)
hist(T1.yrep)


abline(v=T1.y,col="red",lwd=2)


pppval.max <- sum(T1.yrep>=T1.y)/m
print(pppval.max)

# quick check to see how params compare to OLS 
summary(lm(Y ~ full.ghcn$DI.scaled))

# plot mcmc + the parameter distn
coda:::plot.mcmc(samp)
samp.basic.reg <- samp
# save a data frame with beta2 sensitivity and the 
samp.basic.reg.df <- summary(samp)
  
samp.basic.df.sum<- data.frame(mean = samp.df$statistics[2,"Mean"], 
           ci.low = samp.df$quantiles[2,"2.5%"], 
           ci.high = samp.df$quantiles[2,"97.5%"])
  


```

# Create random effects for sites:
```{r}
population_model_site_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[SITE[i]] + beta2[SITE[i]]*DI.scaled[i] + beta3[SITE[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 

#res[i] <- Y[i] - gfunc[i]   
#emp.new[i] ~ dnorm(gfunc[i], sigma)
#res.new[i] <- emp.new[i] - gfunc[i]
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
}

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.0001, 0.0001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)

# predicted Y's
for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[SITEp[i]] + beta2[SITEp[i]]*DI.scaled.p[i] + beta3[SITEp[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 

}




}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)

full.ghcn$site_age <- paste0(full.ghcn$site, "-", full.ghcn$ageclass)
full.ghcn$site_age.code <- as.numeric(as.factor(full.ghcn$site_age))

reg.model.by_s <- jags.model(textConnection(population_model_site_re), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, SITE = as.numeric(full.ghcn$site_age.code), S = unique(full.ghcn$site_age.code)), n.chains = 3, n.adapt = 100)

update(reg.model.by_s, 1000); # Burnin for 1000 samples to start, then go higher later

samp.plot.re <- coda.samples(reg.model.by_s, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3"), 
                    n.chains = 3, n.iter=3000)

summary(samp.plot.re)
plot(samp.plot.re)

gelman.diag(samp.plot.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.plot.re[[1]]
 #Yp.samps    <- samps[,1] 
 alpha.samps <- samps[,1:25] # one alpha for each of 16 sites
 beta1.samps  <- samps[,26:50]
 beta2.samps <- samps[,51:75]
 sigma.samps <- samps[,49]
 sigma_betas <- samps[,50:52]


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0(unique(full.ghcn$site_age)[order(unique(full.ghcn$site_age.code))]))
a$num <- rownames(a)
 
a.m <- melt(a, id.vars=c("num"))
split.list <- strsplit(as.character(a.m$variable),split = "-")
split.list.df <- do.call(rbind, split.list)
a.m$site <- split.list.df[,1]
a.m$ageclass <- split.list.df[,2]
alpha.mplots <- ggplot(a.m, aes(value, fill = ageclass))+geom_density(alpha = 0.5)+theme_black()+xlab("Random Intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0(unique(full.ghcn$site_age)[order(unique(full.ghcn$site_age.code))]))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.m <- melt(b2, id.vars=c("num"))
split.list <- strsplit(as.character(b2.m$variable),split = "-")
split.list.df <- do.call(rbind, split.list)
b2.m$site <- split.list.df[,1]
b2.m$ageclass <- split.list.df[,2]
b2.mplots <- ggplot(b2.m, aes(value, fill = ageclass))+geom_density(alpha = 0.5)+theme_black()+xlab("Drought Index sensitivity")


b2.mplots <-ggplot(b2.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.003)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black(base_size = 18)+scale_fill_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))

b2.mean <- apply(as.matrix(b2[,1:25]), 2, mean)
b2.lower <- apply(as.matrix(b2[,1:25]), 2, function(x) quantile(x, probs = c(0.025)))
b2.upper <- apply(as.matrix(b2[,1:25]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.b2 <- data.frame(b2.mean, b2.lower, b2.upper)
split.list <- strsplit(as.character(row.names(plot.dat.b2)),split = "-")
split.list.df <- do.call(rbind, split.list)
plot.dat.b2$site <- split.list.df[,1]
plot.dat.b2$ageclass <- split.list.df[,2]
#plot.dat.b2$class <- row.names(plot.dat.b2)
plot.dat.b2$ageclass <- factor(plot.dat.b2$ageclass, levels = c("Past", "Modern"))

b2.dots <- ggplot(plot.dat.b2, aes(x = b2.mean, y = ageclass, color = ageclass, size = 2))+geom_errorbarh( xmin = b2.lower, xmax = b2.upper, size = 2,height = 0)+geom_point()+theme_black(base_size = 18)+scale_color_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))+coord_flip()+theme(legend.position = "none")+xlab("Estimated Drought Sensitivity")+facet_wrap(~site)

png(height = 4, width = 8, units = "in", res= 300, "outputs/growth_model/basic_reg_cohort_re/drougt_beta_marginal_distn_bycohort.png")
plot_grid(b2.dots, b2.mplots+coord_flip() +xlim(-0.01, 0.075)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))
dev.off()
 
 
 
# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe, site = 1:16)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(20000, mu, sigma.mn)
  # lines(density(y),col=2)

   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)

Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of D
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_site_re/Ypred_by_drought_site.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(site)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_site_re/Ypred_by_DBH.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(site)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_site_re/Ypred_by_drought_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(site))
dev.off()

# since site 10 is variable, remove:

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_site_re/Ypred_by_drought_DBH_site_site_10_omitted.png")
ggplot(Xp[Xp$site != 10,], aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(site))
dev.off()


```


#this is a model with cohort effects and re effects @ the cohort level rather than the site level:

```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
population_model_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*DI.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 


r1[i] <- Y[i] - gfunc[i]   
}

RSS[1] <- sum(r1^2)

# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(c in 1:length(C)){
beta1[c] ~ dnorm(mu_beta1, inv_beta1)
beta2[c] ~ dnorm(mu_beta2, inv_beta2)
beta3[c] ~ dnorm(mu_beta3, inv_beta3)

r2[c] <- beta1[c] - mu_beta1
r3[c] <- beta2[c] - mu_beta2
r4[c] <- beta3[c] - mu_beta3
}


RSS[2] <- sum(r2^2)
RSS[3] <- sum(r3^2)
RSS[4] <- sum(r4^2)

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)



  
# Contrasts:
    betadiff <- beta2[1]-beta2[2] # difference in modes of pitcher and 1st base positions
    #betadiffProb <- step(betadiff) # returns a 1 if c1Minusc3 > 0


# get Ypred for test data:
for(i in 1:np){
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*DI.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 

}


}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)

msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]

reg.model.by_age <- jags.model(textConnection(population_model_cohort_re), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, cohort = as.numeric(full.ghcn$ageclass), C = unique(full.ghcn$ageclass), np=length(test$year), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass)), n.chains = 3, n.adapt = 100)


update(reg.model.by_age, 1000); # Burnin for 1000 samples to start, then go higher later

samp.age.re <- coda.samples(reg.model.by_age, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "betadiff", "Yp", "RSS[1]", "RSS[2]", "RSS[3]", "RSS[4]"), 
                    n.chains = 3, n.iter=2000, thin = 10)

summary(samp.age.re)
plot(samp.age.re)

gelman.diag(samp.age.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.age.re[[1]]
 RSS <- samps[,1:5]
 samps <- samps[,5:(length(test$year)+15)]
 Yp.samps    <- samps[,1:length(test$year)] 
 alpha.samps <- samps[,(length(test$year)+1):(length(test$year)+2)] # one alpha for each of 16 sites
 beta1.samps  <- samps[,(length(test$year)+3):(length(test$year)+4)]
 beta2.samps <- samps[,(length(test$year)+5):(length(test$year)+6)]
 beta.diff.samps <- samps[,(length(test$year)+7)]
 sigma.samps <- samps[,(length(test$year)+8)]
 sigma_betas <- samps[,(length(test$year)+9):(length(test$year)+11)]

 #RSS:
  rss0 <- function(x) crossprod(x-mean(x))
## Data level
1-mean(RSS[,1])/rss0(Y)
1-mean(RSS[,2])/rss0(Y)
1-mean(RSS[,3])/rss0(Y)
1-mean(RSS[,4])/rss0(Y)
1-mean(RSS[,5])/rss0(Y)
## Group level
1-mean(RSS[,2])/mean(apply(alpha.samps, 1, rss0))
1-mean(RSS[,3])/mean(apply(beta1.samps, 1, rss0))

# plot predicted vs. observed test data:
 png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_re/Ypred_vs_obs.png")
 plot(colMeans(exp(Yp.samps)), test$RWI, xlab = "Mean Posterior Predicted Growth", ylab = "Observed Tree Ring Growth")
 abline(a = 0, b = 1, col = "red")
 dev.off()
 
 
 
png("outputs/growth_model/basic_reg_cohort_re/marginal_alphas.png")
par(mfrow=c(1,3))
hist(alpha.samps[,1], main = "alpha Forest")
hist(alpha.samps[,2], main = "alpha Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_cohort_re/marginal_beta1s.png")
par(mfrow=c(1,3))
hist(beta1.samps[,1], main = "beta2 Forest")
hist(beta1.samps[,2], main = "beta2 Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()


png("outputs/growth_model/basic_reg_cohort_re/marginal_beta1_diff.png")

hist(beta1.diffs, main = "Difference between savanna and forest beta1")
abline(v=0,col="red")
dev.off()

png("outputs/growth_model/basic_reg_cohort_re/marginal_beta2s.png")
par(mfrow=c(1,3))
hist(beta2.samps[,1], main = "beta3 Forest")
hist(beta2.samps[,2], main = "beta3 Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("Random Intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0(c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("Drought Index sensitivity")


b2.mplots <-ggplot(b2.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.003)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black(base_size = 18)+scale_fill_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))

b2.mean <- apply(as.matrix(b2[,1:2]), 2, mean)
b2.lower <- apply(as.matrix(b2[,1:2]), 2, function(x) quantile(x, probs = c(0.025)))
b2.upper <- apply(as.matrix(b2[,1:2]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.b2 <- data.frame(b2.mean, b2.lower, b2.upper)
plot.dat.b2$class <- row.names(plot.dat.b2)
plot.dat.b2$class <- factor(plot.dat.b2$class, levels = c("Past", "Modern"))

b2.dots <- ggplot(plot.dat.b2, aes(x = b2.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = b2.lower, xmax = b2.upper, size = 2,height = 0)+geom_point()+xlim(-0.01, 0.075)+theme_black(base_size = 18)+scale_color_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))+coord_flip()+theme(legend.position = "none")+xlab("Estimated Drought Sensitivity")

png(height = 4, width = 8, units = "in", res= 300, "outputs/growth_model/basic_reg_cohort_re/drougt_beta_marginal_distn_bycohort.png")
plot_grid(b2.dots, b2.mplots+coord_flip() +xlim(-0.01, 0.075)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))
dev.off()


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("DBH Index sensitivity")

library(cowplot)
png(width = 4, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_cohort_re/param_marginal_distn_by_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

 
# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(20000, mu, sigma.mn)
  # lines(density(y),col=2)

   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)

Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of 
Xp$cohort <- ifelse(Xp$cohort == 1, "Past", "Modern")
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_re/Ypred_by_drought_site_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_re/Ypred_by_DBH_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")+theme_black()
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_re/Ypred_by_drought_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(cohort))+theme_black()
dev.off()


```


#this is a model with structure effects and re effects @ the structure (forest vs. savanna) level rather than the site level:

```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
population_model_structure_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[structure[i]] + beta2[structure[i]]*DI.scaled[i] + beta3[structure[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 

res[i] <- Y[i] - gfunc[i]   
emp.new[i] ~ dnorm(gfunc[i], sigma)
res.new[i] <- emp.new[i] - gfunc[i]
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
}

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)


for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[structure.p[i]] + beta2[structure.p[i]]*DI.scaled.p[i] + beta3[structure.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 

}




}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))

full.ghcn <- merge(full.ghcn, structure, by = "site")

reg.model.by_structure <- jags.model(textConnection(population_model_structure_re), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, structure = as.numeric(full.ghcn$structure), SF = unique(full.ghcn$structure), np=length(test$year), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, structure.p = as.numeric(test$structure)), n.chains = 3, n.adapt = 100)

update(reg.model.by_structure, 1000); # Burnin for 1000 samples to start, then go higher later

samp.structure.re <- coda.samples(reg.model.by_structure, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 15)

summary(samp.structure.re)
plot(samp.structure.re)

gelman.diag(samp.structure.re)
acfplot(samp.structure.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.structure.re[[1]]
 saveRDS(samps, "outputs/growth_model/basic_reg_structure_re/samps.rds")
 Yp.samps    <- samps[,1:length(test$site)] 
 alpha.samps <- samps[,(length(test$site)+1):(length(test$site)+2)] # one alpha for each of 16 sites
 beta1.samps  <- samps[,(length(test$site)+3):(length(test$site)+4)]
 beta2.samps <- samps[,(length(test$site)+5):(length(test$site)+6)]
 sigma.samps <- samps[,(length(test$site)+7)]
 sigma_betas <- samps[,(length(test$site)+8):(length(test$site)+10)]
 
 # derived quantities:
 beta1.diffs <- beta1.samps[,1] - beta2.samps[,2]
hist(beta1.diffs)


 
# plot marginal distributions of each parameter:

png("outputs/growth_model/basic_reg_structure_re/marginal_alphas.png")
par(mfrow=c(1,3))
hist(alpha.samps[,1], main = "alpha Forest")
hist(alpha.samps[,2], main = "alpha Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_structure_re/marginal_beta1s.png")
par(mfrow=c(1,3))
hist(beta1.samps[,1], main = "beta2 Forest")
hist(beta1.samps[,2], main = "beta2 Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()


png("outputs/growth_model/basic_reg_structure_re/marginal_beta1_diff.png")

hist(beta1.diffs, main = "Difference between savanna and forest beta1")
abline(v=0,col="red")
dev.off()

png("outputs/growth_model/basic_reg_structure_re/marginal_beta2s.png")
par(mfrow=c(1,3))
hist(beta2.samps[,1], main = "beta3 Forest")
hist(beta2.samps[,2], main = "beta3 Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c("Forest", "Savanna")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+theme_black()+xlab("random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c("Forest", "Savanna")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+theme_black()+xlab("Drought slopes")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Forest", "Savanna")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+theme_black()+xlab("DBH random slopes")

library(cowplot)
png(width = 4, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_structure_re/param_marginal_distn_by_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()


# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 

 # plot predicted vs. observed:
 png(width = 4, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_structure_re/pred_vs_obs.png")
 plot(colMeans(exp(Yp.samps)), test$RWI, xlab = "Predicted Growth", ylab = "Observed Growth")
abline(a = 0, b = 1, col = "red")
dev.off()


# calculate MSE:

MSE1   <- mean((colMeans(exp(Yp.samps))-test$RWI)^2)
BIAS1  <- mean(colMeans(exp(Yp.samps))-test$RWI)
#AVESD1 <- mean(post_sd1)
#COV1   <- mean(Ytest>post_low1 & Ytest<post_high1)

# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  structure= 1:2)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha.samps[,Xp[j,3]] + beta1.samps[,Xp[j,3]]*Xp[j,1] + beta2.samps[,Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- mu #rnorm(20000, mu, sigma.mn)
  
}

ypred.df <- do.call(rbind, ypred)
y.df <- as.data.frame(ypred.df)
Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of 
Xp$structure <- ifelse(Xp$structure == 1, "Forest", "Savanna")
Xp$number <- rownames(Xp)

y.df$number <- 1:length(y.df$V1)
y.df <- merge(Xp, y.df, by = "number")


y.df.m <- melt(y.df, id.vars = c("number", "Var1", "Var2", "structure"))


ggplot(y.df.m, aes(Var1, value, col = structure))+geom_boxplot()

#DBH + DI on predicted growth
png("outputs/growth_model/basic_reg_structure_re/predicted_y.png")
#par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

#plot(density(d13pred.df), main = "d13pred, line = d13data")
#abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()
# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_structure_re/Ypred_by_drought_structure.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(structure)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")


dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_structure_re/Ypred_by_DBH_structure.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(structure)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_structure_re/Ypred_by_drought_DBH_structure.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(structure))
dev.off()


```
# could make a model with site or stand structure by ageclass as the factor to take random effects on:
```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
population_model_structure_x_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[struct.cohort[i]] + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 

#r1[i] <- Y[i] - gfunc[i]   

}

#RSS[1] <- sum(r1^2)

# Prediction
  for(i in 1:np){
    Yp[i]  ~ dnorm(mup[i],inv.var)
    mup[i] <- beta1[struct.cohort.p[i]] + beta2[struct.cohort.p[i]]*DI.scaled.p[i] + beta3[struct.cohort.p[i]]*DBH.scaled.p[i] 
  }

# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)

#r2[s] <- a[j] - mu_beta1
}
#RSS[2] <- sum(r2^2)


# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)






}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))



library(caTools)
msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]

saveRDS(train, "outputs//growth_model/basic_reg_struct_x_cohort_re/train.rds")
saveRDS(test, "outputs//growth_model/basic_reg_struct_x_cohort_re/test.rds")

# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)


reg.model.by_structure_x_cohort <- jags.model(textConnection(population_model_structure_x_cohort_re), 
                    data = list(Y=log(full.ghcn$RWI), n=length(full.ghcn$RWI), DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, struct.cohort = as.numeric(full.ghcn$struct.cohort.code), SF = unique(full.ghcn$struct.cohort.code), np = length(test$DBH.scaled),
   struct.cohort.p = as.numeric(test$struct.cohort.code), DBH.scaled.p = test$DBH.scaled, DI.scaled.p = test$DI.scaled), n.chains = 3, n.adapt = 100)

update(reg.model.by_structure_x_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


samp.structure.cohort.re <- coda.samples(reg.model.by_structure_x_cohort, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 15)

summary(samp.structure.cohort.re)
plot(samp.structure.cohort.re)

gelman.diag(samp.structure.cohort.re)
acfplot(samp.structure.cohort.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.structure.cohort.re[[1]]
 saveRDS(samps, "outputs//growth_model/basic_reg_struct_x_cohort_re/samps.rds")
  samps <- readRDS("outputs//growth_model/basic_reg_struct_x_cohort_re/samps.rds")
 #Yp.samps    <- samps[,1] 
 Yp.samps <- samps[,1:(length(test$RWI))] 
 
 alpha.samps  <- samps[,(length(test$RWI)+ 1):(length(test$RWI)+ 4)]# one alpha for each of 4 cohort-strcuture groups
 beta2.samps <- samps[,(length(test$RWI)+ 5):(length(test$RWI)+ 8)]
 beta3.samps <- samps[,(length(test$RWI)+ 9):(length(test$RWI)+ 12)]
 sigma.samps <- samps[,(length(test$RWI)+ 13)]
 sigma_betas <- samps[,(length(test$RWI)+ 14):(length(test$RWI)+ 16)]

 
# plot predicted vs. observed:
test$mean.Y <- colMeans(exp(Yp.samps))
 
plot(test$mean.Y, test$RWI)
abline(a= 0, b = 1)
png(height = 5, width = 5, units = "in", res = 300, "outputs/growth_model/basic_reg_struct_x_cohort_re/predicted_vs_obs.png")
ggplot(test, aes(mean.Y, RWI))+geom_point(col = "white", size = 0.5)+geom_abline(intercept = 0, slope = 1, col = "grey")+theme_black()+ylim(0,4)+xlim(0.5,1.5)+ylab("Observed")+xlab("Predicted")
dev.off()


# get difference between beta2.samps:
oneminustwo <- beta2.samps[,1] - beta2.samps[,2]
oneminusthree <- beta2.samps[,1] - beta2.samps[,3]
oneminusfour <- beta2.samps[,1] - beta2.samps[,4]
twominusthree <- beta2.samps[,2] - beta2.samps[,3]
twominusfour <- beta2.samps[,2] - beta2.samps[,4]
threeminusfour <- beta2.samps[,3] - beta2.samps[,4]
# calculate MSPE
# get posterior predictive density

# plot marginal distributions of each parameter:
png("outputs/growth_model/basic_reg_struct_x_cohort_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Forest")
hist(alpha.samps[,2], main = "alpha Modern-Forest")
hist(alpha.samps[,3],  main = "alpha Past-Savanna ")
hist(alpha.samps[,4],  main = "alpha Modern-Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_struct_x_cohort_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Forest")
hist(beta2.samps[,2], main = "beta2 Modern-Forest")
hist(beta2.samps[,3],  main = "beta2 Past-Savanna")
hist(beta2.samps[,4],  main = "beta2 Modern-Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/basic_reg_struct_x_cohort_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Forest")
hist(beta3.samps[,2], main = "beta3 Modern-Forest")
hist(beta3.samps[,3],  main = "beta3 Past-Savanna")
hist(beta3.samps[,4],  main = "beta3 Modern-Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(train$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0(c(unique(train$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Drought Index slope")

b2.mplots <-ggplot(b2.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.003)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black(base_size = 16)+scale_fill_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))

b2.mean <- apply(as.matrix(b2[,1:4]), 2, mean)
b2.lower <- apply(as.matrix(b2[,1:4]), 2, function(x) quantile(x, probs = c(0.025)))
b2.upper <- apply(as.matrix(b2[,1:4]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.b2 <- data.frame(b2.mean, b2.lower, b2.upper)
plot.dat.b2$class <- row.names(plot.dat.b2)

plot.dat.b2$class <- factor(plot.dat.b2$class, levels = c( "Past-Forest", "Past-Savanna", "Modern-Forest", "Modern-Savanna"))
b2.dots <- ggplot(plot.dat.b2, aes(x = b2.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = b2.lower, xmax = b2.upper, size = 2,height = 0)+geom_point()+xlim(0, 0.15)+theme_black(base_size = 16)+scale_color_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))+coord_flip()+theme(legend.position = "none")+xlab("Estimated Drought Sensitivity")

png(height = 6, width = 12, units = "in", res = 300,"outputs/growth_model/basic_reg_struct_x_cohort_re/drougt_beta_marginal_distn_bycohort.png")
plot_grid(b2.dots+ xlim(0, 0.15), b2.mplots+coord_flip()+ xlim(0, 0.15)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()), rel_widths = c(1,0.6))
dev.off()

# plot slightly differently:
plot.dat.b2$forestclass <- ifelse(plot.dat.b2$class %in% c("Past-Forest", "Modern-Forest"), "Forest", "Savanna")

plot.dat.b2$ageclass <- ifelse(plot.dat.b2$class %in% c("Past-Forest", "Past-Savanna"), "Past", "Modern")
plot.dat.b2$ageclass <- factor(plot.dat.b2$ageclass, levels= c("Past", "Modern"))

b2.dots.2 <- ggplot(plot.dat.b2, aes(x = b2.mean, y = ageclass, color = ageclass, size = 2))+geom_errorbarh( xmin = b2.lower, xmax = b2.upper, size = 2,height = 0)+geom_point()+xlim(0, 0.15)+theme_black(base_size = 18)+facet_wrap(~forestclass)+scale_color_manual(values = c("Past"='blue',
"Modern"='red'))+coord_flip()+theme(legend.position = "none", axis.title.x = element_blank())+xlab("Estimated Drought Sensitivity")

png(width = 5, height = 4, units = "in", res = 300, "outputs/growth_model/basic_reg_struct_x_cohort_re/param_marginal_distn_bycohort_struct_rb.png")
b2.dots.2
dev.off()

b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(train$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("DBH slope")

library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_struct_x_cohort_re/param_marginal_distn_bycohort_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()


Yp <- data.frame(Yp.samps)
colnames(Yp) <- c(paste0("YP-",c(unique(full.ghcn$struct.cohort))))
Yp$num <- rownames(Yp)
Yp.m <- melt(Yp, id.vars=c("num"))
Yp.m$DBHindex <- Xp$Var2
Yp.m$DIindex <- Xp$Var1
Yp.m$struct.cohort <- Xp$struct.cohort
ggplot(Yp.m, aes(value, color = as.factor(Yp.m$struct.cohort)))+geom_density(alpha = 0.5)+theme_bw()
library(ggridges)

ggplot(Yp.m, aes(x = value, y = as.factor(DIindex))) + 
  geom_density_ridges()

ggplot(full.ghcn, aes(x = log(RWI), y = as.factor(struct.cohort))) + 
  geom_density_ridges()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta2.samps)
 beta2.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 ypred.yp <- list()
 diff <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)
  # lines(density(y),col=2)
   #ypred.yp[[j]] <- Yp.samps[,j]
   #diff[[j]] <- ypred[[j]] - Yp.samps[[j]]
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
#diff.df <- do.call(rbind, diff)
#ypred.yp.df <- do.call(rbind, ypred.yp)

Xp$MeanY <- exp(rowMeans(ypred.df))
#Xp$MeanYhat <- exp(rowMeans(ypred.yp.df))# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
dev.off()


```


# model for cohort effects and site level effects, heirarchically:
```{r}

cohort_model_site_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*DI.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)



}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)


for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*DI.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 
}

}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode


msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]


cohort.model.re <- jags.model(textConnection(cohort_model_site_re), 
                    data = list(Y=log(train$RWI), n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, cohort = as.numeric(train$ageclass), S = unique(train$ageclass),
                    plot = as.numeric(train$site), ind = unique(train$site), np = length(test$DBH.scaled), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass), SP = unique(test$ageclass),
                    plot.p = as.numeric(test$site), ind.p = unique(test$site)), n.chains = 3, n.adapt = 100)

update(cohort.model.re, 2000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(cohort.model.re, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2", "sigma_beta3", "mu_beta1", "mu_beta2", "mu_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 10)

summary(samp)
traceplot(samp)
gelman.diag(samp)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp[[1]]
 saveRDS(samps, "outputs/growth_model/basic_reg_cohort_site_re/samps.rds")
samps <-  readRDS("outputs/growth_model/basic_reg_cohort_site_re/samps.rds")
 Yp.samps    <- samps[,1:2780] 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,2781:2782]
 beta2.samps <- samps[,2783:2784]
 beta3.samps <- samps[,2785:2786]
 mu_beta1.samps <- samps[,2787:2800]
 mu_beta2.samps <- samps[,2801:2814]
 mu_beta3.samps <- samps[,2815:2828]
 sigma.samps <- samps[,2829]
 sigma_betas <- samps[,2830:2832]

png("outputs/growth_model/basic_reg_cohort_site_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past")
hist(alpha.samps[,2], main = "alpha Modern")
#hist(alpha.samps[,3],  main = "alpha Past-Forest")
#hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_cohort_site_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta2.samps[,2], main = "beta2 Modern-Savanna")
#hist(beta2.samps[,3],  main = "beta2 Past-Forest")
#hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()





png("outputs/growth_model/basic_reg_cohort_site_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
#hist(beta3.samps[,3],  main = "beta3 Past-Forest")
#hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_re/marginal_mu_beta2s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta2.samps[,i], main = paste(colnames(mu_beta2.samps)[i]))
}
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_re/marginal_mu_beta3s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta3.samps[,i], main = paste(colnames(mu_beta3.samps)[i]))
}
dev.off()

png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_re/marginal_mu_beta1s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta1.samps))){
  hist(mu_beta1.samps[,i], main = paste(colnames(mu_beta1.samps)[i]))
}
dev.off()

# plot predicted vs. observed:
png("outputs/growth_model/basic_reg_cohort_site_re/pred_vs_obs.png")
plot(colMeans(exp(Yp.samps)), test$RWI) 
abline(a = 0, b = 1, col = "red")
dev.off()



# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0( c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bw = 0.005)+theme_bw()+xlab("Random intercepts")+theme_black()

a.mean <- apply(as.matrix(a[,1:2]), 2, mean)
a.lower <- apply(as.matrix(a[,1:2]), 2, function(x) quantile(x, probs = c(0.025)))
a.upper <- apply(as.matrix(a[,1:2]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat <- data.frame(a.mean, a.lower, a.upper)
plot.dat$class <- row.names(plot.dat)

a.dots <- ggplot(plot.dat, aes(x = a.mean,y = class, color = class))+geom_errorbarh( xmin = a.lower, xmax = a.upper, size = 1,height = 0)+geom_point()+xlim(-0.1, 0.05)+theme_black()+coord_flip()+theme(legend.position = "none")+xlab("Estimated Intercept")

plot_grid(a.dots, alpha.mplots+coord_flip()+ xlim(-0.1, 0.05)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))



b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0(c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <-ggplot(b2.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bw = 0.005)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black()

b2.mean <- apply(as.matrix(b2[,1:2]), 2, mean)
b2.lower <- apply(as.matrix(b2[,1:2]), 2, function(x) quantile(x, probs = c(0.025)))
b2.upper <- apply(as.matrix(b2[,1:2]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.b2 <- data.frame(b2.mean, b2.lower, b2.upper)
plot.dat.b2$class <- row.names(plot.dat.b2)

b2.dots <- ggplot(plot.dat.b2, aes(x = b2.mean, y = class, color = class))+geom_errorbarh( xmin = b2.lower, xmax = b2.upper, size = 1,height = 0)+geom_point()+xlim(0, 0.15)+theme_black()+coord_flip()+theme(legend.position = "none")+xlab("Estimated Drought Sensitivity")

png("outputs/growth_model/basic_reg_cohort_site_re/drougt_beta_marginal_distn_bycohort.png")
plot_grid(b2.dots, b2.mplots+coord_flip()+ xlim(0, 0.15)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))
dev.off()



b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("DBH slope")+theme_black()

library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_cohort_site_re/param_marginal_distn_bycohort.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 beta3.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
 #mu_beta1.samps <- colMeans(mu_beta1.samps) 
 #mu_beta2.samps <- colMeans(mu_beta2.samps) 
 #mu_beta3.samps <- colMeans(mu_beta3.samps) 


# get posterior predictions:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2, site = as.numeric(unique(full.ghcn$site)))
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:



 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 
 
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

        
        alpha1.mn <- rnorm(1000, mu_beta1.samps[Xp[j,4]], mean(sigma_betas[,1]) ) # check the sigma betas
        beta2.mn <- rnorm(1000, mu_beta2.samps[Xp[j,4]], mean(sigma_betas[,2]) ) # check the sigma betas
        beta3.mn <- rnorm(1000, mu_beta3.samps[Xp[j,3]], mean(sigma_betas[,3]) ) # check the sigma betas
       
   mu <- alpha1.mn + beta2.mn*Xp[j,1] + beta2.mn*Xp[j,2]   # use
   
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   
   ypred[[j]]  <- mu
  # lines(density(y),col=2)
   
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)


Xp$MeanY <- exp(rowMeans(ypred.df))

Xp$cohort <- ifelse(Xp$cohort == 2, "Past",  
                       ifelse(Xp$cohort == 1, "Modern",NA))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1, MeanY, color = as.factor(site), shape = as.factor(cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(cohort))
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site))
dev.off()


png(height = 10, width = 10, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site) + as.factor(cohort))
dev.off()

```
# this is the same as above, but we include both cohort and structure as RE
```{r}

site_model_structure_x_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[struct.cohort[i]] + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 


}

# Prediction
  for(i in 1:np){
    Yp[i]  ~ dnorm(mup[i],inv.var)
    mup[i] <- beta1[struct.cohort.p[i]] + beta2[struct.cohort.p[i]]*DI.scaled.p[i] + beta3[struct.cohort.p[i]]*DBH.scaled.p[i] 
  }

# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)
}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)





}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)
#need to define site level structures:




full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))



library(caTools)
msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]



# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 
 Xp <- full.probe
 np <- length(Xp$Var1)


reg.model.site_structure_x_cohort <- jags.model(textConnection(site_model_structure_x_cohort_re ), 
                    data = list(Y=log(train$RWI), n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, struct.cohort = as.numeric(train$struct.cohort.code), S = unique(train$struct.cohort.code), plot = as.numeric(train$site), ind = unique(train$site),np = length(test$DBH.scaled),
   struct.cohort.p = as.numeric(test$struct.cohort.code), DBH.scaled.p = test$DBH.scaled, DI.scaled.p = test$DI.scaled), n.chains = 3, n.adapt = 100)

update(reg.model.site_structure_x_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


samp.structure.site.cohort.re <- coda.samples(reg.model.site_structure_x_cohort, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 15)

summary(samp.structure.site.cohort.re)
plot(samp.structure.site.cohort.re)

gelman.diag(samp.structure.site.cohort.re)
acfplot(samp.structure.site.cohort.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.structure.site.cohort.re[[1]]
 saveRDS(samps, "outputs/growth_model/site_reg_structure_cohort_re/samps.rds")
 #Yp.samps    <- samps[,1] 
 Yp.samps <- samps[,1:length(test$RWI)] 
 alpha.samps  <- samps[,(length(test$RWI)+1):(length(test$RWI)+4)]# one alpha for each of 4 cohort-strcuture groups
 beta2.samps <- samps[,(length(test$RWI)+5):(length(test$RWI)+8)]
 beta3.samps <- samps[,(length(test$RWI)+9):(length(test$RWI)+12)]
 sigma.samps <- samps[,(length(test$RWI)+13)]
 sigma_betas <- samps[,(length(test$RWI)+14):(length(test$RWI)+16)]

 
# plot predicted vs. observed:
test$mean.Y <- colMeans(exp(Yp.samps))
png("outputs/growth_model/site_reg_structure_cohort_re/marginal_alphas.png")
plot(colMeans(exp(Yp.samps)), test$RWI)
abline(a = 0, b = 1, col = "red")
 dev.off()
ggplot(test, aes(RWI, mean.Y))+geom_point()+geom_abline(intercept = 0, slope = 1,  color = "red")

# get difference between beta2.samps:
oneminustwo <- beta2.samps[,1] - beta2.samps[,2]
oneminusthree <- beta2.samps[,1] - beta2.samps[,3]
oneminusfour <- beta2.samps[,1] - beta2.samps[,4]
twominusthree <- beta2.samps[,2] - beta2.samps[,3]
twominusfour <- beta2.samps[,2] - beta2.samps[,4]
threeminusfour <- beta2.samps[,3] - beta2.samps[,4]
# calculate MSPE
# get posterior predictive density

# plot marginal distributions of each parameter:
png("outputs/growth_model/site_reg_structure_cohort_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Forest")
hist(alpha.samps[,2], main = "alpha Modern-Forest")
hist(alpha.samps[,3],  main = "alpha Past-Savanna ")
hist(alpha.samps[,4],  main = "alpha Modern-Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/site_reg_structure_cohort_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Forest")
hist(beta2.samps[,2], main = "beta2 Modern-Forest")
hist(beta2.samps[,3],  main = "beta2 Past-Savanna")
hist(beta2.samps[,4],  main = "beta2 Modern-Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/site_reg_structure_cohort_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Forest")
hist(beta3.samps[,2], main = "beta3 Modern-Forest")
hist(beta3.samps[,3],  main = "beta3 Past-Savanna")
hist(beta3.samps[,4],  main = "beta3 Modern-Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0(c(unique(train$struct.cohort)[order(unique(train$struct.cohort.code))])))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <-ggplot(a.m, aes(value,1, fill = variable))+stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.05, 0.95), bandwidth = 0.005, alpha = 0.5)+theme_black()+ylab("frequency")+xlab(" random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0(c(unique(train$struct.cohort)[order(unique(train$struct.cohort.code))])))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value,1, fill = variable))+stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.05, 0.95), bandwidth = 0.005, alpha = 0.5)+theme_black()+ylab("frequency")+xlab("Drought random slopes")

b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0(c(unique(train$struct.cohort)[order(unique(train$struct.cohort.code))])))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value,1, fill = variable))+stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.05, 0.95), bandwidth = 0.005, alpha = 0.5)+theme_black()+ylab("frequency")+xlab("DBH random slopes")


library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/site_reg_structure_cohort_re/param_marginal_distn_bycohort_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()


Yp <- data.frame(Yp.samps)
colnames(Yp) <- c(paste0("YP-",test$site))
Yp$num <- rownames(Yp)
Yp.m <- melt(Yp, id.vars=c("num"))
#Yp.m$DBHindex <- Xp$Var2
#Yp.m$DIindex <- Xp$Var1
#Yp.m$struct.cohort <- Xp$struct.cohort

ggplot(Yp.m, aes(value, color = as.factor(Yp.m$variable)))+geom_density(alpha = 0.5)+theme_bw()

library(ggridges)

ggplot(Yp.m, aes(x = value, y = as.factor(DIindex))) + 
  geom_density_ridges()

ggplot(full.ghcn, aes(x = log(RWI), y = as.factor(struct.cohort))) + 
  geom_density_ridges()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta2.samps)
 beta2.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 ypred.yp <- list()
 diff <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)
  # lines(density(y),col=2)
   #ypred.yp[[j]] <- Yp.samps[,j]
   #diff[[j]] <- ypred[[j]] - Yp.samps[[j]]
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
#diff.df <- do.call(rbind, diff)
#ypred.yp.df <- do.call(rbind, ypred.yp)

Xp$MeanY <- exp(rowMeans(ypred.df))
#Xp$MeanYhat <- exp(rowMeans(ypred.yp.df))# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/site_reg_structure_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+xlab("Drought Index")+geom_point()+ylab("predicted growth")+stat_smooth()
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/site_reg_structure_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")+stat_smooth()
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/site_reg_structure_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
dev.off()


```

# this is the same as above, but we include both cohort and structure as RE, but no random slopes:
```{r}

site_model_structure_x_cohort_re_slopes <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1 + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 


}

# Prediction
  for(i in 1:np){
    Yp[i]  ~ dnorm(mup[i],inv.var)
    mup[i] <- beta1 + beta2[struct.cohort.p[i]]*DI.scaled.p[i] + beta3[struct.cohort.p[i]]*DBH.scaled.p[i] 
  }

# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
#beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)
}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
#mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

beta1 ~ dnorm(0, inv_beta1)
inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)





}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))



library(caTools)
msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]



# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 
 Xp <- full.probe
 np <- length(Xp$Var1)


reg.model.site_structure_x_cohort_slopes <- jags.model(textConnection(site_model_structure_x_cohort_re_slopes ), 
                    data = list(Y=log(train$RWI), n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, struct.cohort = as.numeric(train$struct.cohort.code), S = unique(train$struct.cohort.code), plot = as.numeric(train$site), ind = unique(train$site),np = length(test$DBH.scaled),
   struct.cohort.p = as.numeric(test$struct.cohort.code), DBH.scaled.p = test$DBH.scaled, DI.scaled.p = test$DI.scaled), n.chains = 3, n.adapt = 100)

update(reg.model.site_structure_x_cohort_slopes, 1000); # Burnin for 1000 samples to start, then go higher later


samp.structure.site.cohort.re.slopes <- coda.samples(reg.model.site_structure_x_cohort_slopes, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 15)

summary(samp.structure.site.cohort.re.slopes)
plot(samp.structure.site.cohort.re.slopes)

gelman.diag(samp.structure.site.cohort.re.slopes)
acfplot(samp.structure.site.cohort.re.slopes)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.structure.site.cohort.re.slopes[[1]]
 saveRDS(samps, "outputs/growth_model/site_reg_structure_cohort_re.slopes/samps.rds")
 #Yp.samps    <- samps[,1] 
 Yp.samps <- samps[,1:length(test$RWI)] 
 alpha.samps  <- samps[,(length(test$RWI)+1)]# one alpha for each of 4 cohort-strcuture groups
 beta2.samps <- samps[,(length(test$RWI)+2):(length(test$RWI)+6)]
 beta3.samps <- samps[,(length(test$RWI)+7):(length(test$RWI)+10)]
 sigma.samps <- samps[,(length(test$RWI)+11)]
 sigma_betas <- samps[,(length(test$RWI)+12):(length(test$RWI)+13)]

 
# plot predicted vs. observed:
test$mean.Y <- colMeans(exp(Yp.samps))
png("outputs/growth_model/site_reg_structure_cohort_re.slopes/marginal_alphas.png")
plot(colMeans(exp(Yp.samps)), test$RWI)
abline(a = 0, b = 1, col = "red")
 dev.off()
ggplot(test, aes(RWI, mean.Y))+geom_point()+geom_abline(intercept = 0, slope = 1,  color = "red")

# get difference between beta2.samps:
oneminustwo <- beta2.samps[,1] - beta2.samps[,2]
oneminusthree <- beta2.samps[,1] - beta2.samps[,3]
oneminusfour <- beta2.samps[,1] - beta2.samps[,4]
twominusthree <- beta2.samps[,2] - beta2.samps[,3]
twominusfour <- beta2.samps[,2] - beta2.samps[,4]
threeminusfour <- beta2.samps[,3] - beta2.samps[,4]
# calculate MSPE
# get posterior predictive density

# plot marginal distributions of each parameter:
png("outputs/growth_model/site_reg_structure_cohort_re.slopes/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Forest")
hist(alpha.samps[,2], main = "alpha Modern-Forest")
hist(alpha.samps[,3],  main = "alpha Past-Savanna ")
hist(alpha.samps[,4],  main = "alpha Modern-Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/site_reg_structure_cohort_re.slopes/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Forest")
hist(beta2.samps[,2], main = "beta2 Modern-Forest")
hist(beta2.samps[,3],  main = "beta2 Past-Savanna")
hist(beta2.samps[,4],  main = "beta2 Modern-Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/site_reg_structure_cohort_re.slopes/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Forest")
hist(beta3.samps[,2], main = "beta3 Modern-Forest")
hist(beta3.samps[,3],  main = "beta3 Past-Savanna")
hist(beta3.samps[,4],  main = "beta3 Modern-Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0(c(unique(train$struct.cohort)[order(unique(train$struct.cohort.code))])))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <-ggplot(a.m, aes(value,1, fill = variable))+stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.05, 0.95), bandwidth = 0.005, alpha = 0.5)+theme_black()+ylab("frequency")+xlab(" random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0(c(unique(train$struct.cohort)[order(unique(train$struct.cohort.code))])))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <-ggplot(b2.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.003)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black()+scale_fill_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))

b2.mean <- apply(as.matrix(b2[,1:4]), 2, mean)
b2.lower <- apply(as.matrix(b2[,1:4]), 2, function(x) quantile(x, probs = c(0.025)))
b2.upper <- apply(as.matrix(b2[,1:4]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.b2 <- data.frame(b2.mean, b2.lower, b2.upper)
plot.dat.b2$class <- row.names(plot.dat.b2)

b2.dots <- ggplot(plot.dat.b2, aes(x = b2.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = b2.lower, xmax = b2.upper, size = 2,height = 0)+geom_point()+xlim(0, 0.15)+theme_black()+scale_color_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))+coord_flip()+theme(legend.position = "none")+xlab("Estimated Drought Sensitivity")

png("outputs/growth_model/site_reg_structure_cohort_re.slopes/drougt_beta_marginal_distn_bycohort.png")
plot_grid(b2.dots, b2.mplots+coord_flip()+ xlim(0, 0.15)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))
dev.off()


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0(c(unique(train$struct.cohort)[order(unique(train$struct.cohort.code))])))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value,1, fill = variable))+stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.05, 0.95), bandwidth = 0.005, alpha = 0.5)+theme_black()+ylab("frequency")+xlab("DBH random slopes")

 ggplot(b3.m, aes(value,1, fill = variable))+stat_density_ridges(quantile_lines = TRUE, quantiles = c(0.05, 0.95), bandwidth = 0.005, alpha = 0.5)+theme_black()+ylab("frequency")+xlab("DBH random slopes")

b3.boxplots <- ggplot(b3.m, aes(y = value, fill = variable))+geom_boxplot(alpha = 0.5)+theme_bw()+xlab("DBH slope")+theme_black()

library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/site_reg_structure_cohort_re.slopes/param_marginal_distn_bycohort_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()


Yp <- data.frame(Yp.samps)
colnames(Yp) <- c(paste0("YP-",test$site))
Yp$num <- rownames(Yp)
Yp.m <- melt(Yp, id.vars=c("num"))
#Yp.m$DBHindex <- Xp$Var2
#Yp.m$DIindex <- Xp$Var1
#Yp.m$struct.cohort <- Xp$struct.cohort

ggplot(Yp.m, aes(value, color = as.factor(Yp.m$variable)))+geom_density(alpha = 0.5)+theme_bw()

library(ggridges)

ggplot(Yp.m, aes(x = value, y = as.factor(DIindex))) + 
  geom_density_ridges()

ggplot(full.ghcn, aes(x = log(RWI), y = as.factor(struct.cohort))) + 
  geom_density_ridges()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta2.samps)
 beta2.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 ypred.yp <- list()
 diff <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)
  # lines(density(y),col=2)
   #ypred.yp[[j]] <- Yp.samps[,j]
   #diff[[j]] <- ypred[[j]] - Yp.samps[[j]]
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
#diff.df <- do.call(rbind, diff)
#ypred.yp.df <- do.call(rbind, ypred.yp)

Xp$MeanY <- exp(rowMeans(ypred.df))
#Xp$MeanYhat <- exp(rowMeans(ypred.yp.df))# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/site_reg_structure_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+xlab("Drought Index")+geom_point()+ylab("predicted growth")+stat_smooth()
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/site_reg_structure_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")+stat_smooth()
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/site_reg_structure_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
dev.off()


```

# model for cohort effects with summer VPD instead of PDSI
```{r}

cohort_model_site_VPD_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*VPD.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)
}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)


for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*VPD.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 
}

}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
full.ghcn$jja.VPDmax.scaled <- as.vector(scale(full.ghcn$jja.VPDmax, center = TRUE, scale = TRUE))


msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]


cohort.model.VPD.re <- jags.model(textConnection(cohort_model_site_VPD_re ), 
                    data = list(Y=log(full.ghcn$RWI), n=length(full.ghcn$RWI), VPD.scaled = full.ghcn$jja.VPDmax.scaled, DBH.scaled = full.ghcn$DBH.scaled, cohort = as.numeric(full.ghcn$ageclass), S = unique(full.ghcn$ageclass),
                    plot = as.numeric(full.ghcn$site), ind = unique(full.ghcn$site), np = length(test$DBH.scaled),  VPD.scaled.p = test$jja.VPDmax.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass), SP = unique(test$ageclass),
                    plot.p = as.numeric(test$site), ind.p = unique(test$site)), n.chains = 3, n.adapt = 100)

update(cohort.model.VPD.re , 2000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(cohort.model.VPD.re , 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2", "sigma_beta3", "mu_beta1", "mu_beta2", "mu_beta3", "Yp"), 
                    n.chains = 3, n.iter=2000, thin = 10)

summary(samp)
traceplot(samp)
gelman.diag(samp)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp[[1]]
 saveRDS(samps, "outputs/growth_model/basic_reg_cohort_site_VPD_re/samps.rds")
 Yp.samps    <- samps[,1:2756] 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,2757:2758]
 beta2.samps <- samps[,2759:2760]
 beta3.samps <- samps[,2761:2762]
 mu_beta1.samps <- samps[,2763:2776]
 mu_beta2.samps <- samps[,2777:2790]
 mu_beta3.samps <- samps[,2791:2804]
 sigma.samps <- samps[,2805]
 sigma_betas <- samps[,2806:2808]

png("outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past")
hist(alpha.samps[,2], main = "alpha Modern")
#hist(alpha.samps[,3],  main = "alpha Past-Forest")
#hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta2.samps[,2], main = "beta2 Modern-Savanna")
#hist(beta2.samps[,3],  main = "beta2 Past-Forest")
#hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()





png("outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
#hist(beta3.samps[,3],  main = "beta3 Past-Forest")
#hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_mu_beta2s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta2.samps[,i], main = paste(colnames(mu_beta2.samps)[i]))
}
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_mu_beta3s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta3.samps[,i], main = paste(colnames(mu_beta3.samps)[i]))
}
dev.off()

png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_mu_beta1s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta1.samps))){
  hist(mu_beta1.samps[,i], main = paste(colnames(mu_beta1.samps)[i]))
}
dev.off()

# plot predicted vs. observed:
png("outputs/growth_model/basic_reg_cohort_site_VPD_re/pred_vs_obs.png")
plot(colMeans(exp(Yp.samps)), test$RWI) 
abline(a = 0, b = 1, col = "red")
dev.off()



# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-", c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Random intercepts")+theme_black()


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("VPD Index slope")+theme_black()


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("DBH slope")+theme_black()

library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_cohort_site_VPD_re/param_marginal_distn_bycohort.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(alpha.samps)
 beta2.mn  <- colMeans(beta2.samps)
 beta3.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
 #mu_beta1.samps <- colMeans(mu_beta1.samps) 
 #mu_beta2.samps <- colMeans(mu_beta2.samps) 
 #mu_beta3.samps <- colMeans(mu_beta3.samps) 


# get posterior predictions:
 DIprobe <- seq(range(full.ghcn$jja.VPDmax.scaled)[1], range(full.ghcn$jja.VPDmax.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2, site = as.numeric(unique(full.ghcn$site)))
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:



 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 
 
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

        
        alpha1.mn <- rnorm(1000, mu_beta1.samps[Xp[j,4]], mean(sigma_betas[,1]) ) # check the sigma betas
        beta2.mn <- rnorm(1000, mu_beta2.samps[Xp[j,4]], mean(sigma_betas[,2]) ) # check the sigma betas
        beta3.mn <- rnorm(1000, mu_beta3.samps[Xp[j,3]], mean(sigma_betas[,3]) ) # check the sigma betas
       
   mu <- alpha1.mn + beta2.mn*Xp[j,1] + beta2.mn*Xp[j,2]   # use
   
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   
   ypred[[j]]  <- mu
  # lines(density(y),col=2)
   
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)


Xp$MeanY <- rowMeans(exp(ypred.df))

Xp$cohort <- ifelse(Xp$cohort == 2, "Past",  
                       ifelse(Xp$cohort == 1, "Modern",NA))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_VPD_struct_x_cohort.png")
ggplot(Xp, aes(Var1, MeanY, color = as.factor(site), shape = as.factor(cohort)))+geom_point()+xlab("VPD Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_VPD_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(cohort))
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_VPD_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site))
dev.off()


png(height = 10, width = 10, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site_cohort.png")
ggplot(Xp[!Xp$site %in% "10",], aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site) + as.factor(cohort))
dev.off()

```

# cohort model for only comparable drought years:
# model for cohort effects and site level effects, heirarchically:
```{r}
cohort_model_dry_site_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*DI.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)
}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)

# predictions for the model:
for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*DI.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 
}


}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode

dry <- quantile(full.ghcn$JJA.pdsi, 0.25) # value of the driest years
wet <- quantile(full.ghcn$JJA.pdsi, 0.75) # value of the wettest years

pre.dry <- full.ghcn[full.ghcn$year < 1950 & full.ghcn$Jul.pdsi <= dry & full.ghcn$ageclass %in% "Past",]
pre.dry$class <- "pre-1950"
pre.dry$climclass <- "Dry_0.25"
post.dry <- full.ghcn[full.ghcn$year >=1950 & full.ghcn$Jul.pdsi <= dry & full.ghcn$ageclass %in% "Modern" ,]
post.dry$class <- "post-1950"
post.dry$climclass <- "Dry_0.25"

pre.wet <- full.ghcn[full.ghcn$year < 1950 & full.ghcn$Jul.pdsi >= wet & full.ghcn$ageclass %in% "Past",]
pre.wet$class <- "pre-1950"
pre.wet$climclass <- "Wet_0.25"
post.wet <- full.ghcn[full.ghcn$year >=1950 & full.ghcn$Jul.pdsi >= wet & full.ghcn$ageclass %in% "Modern" ,]
post.wet$class <- "post-1950"
post.wet$climclass <- "Wet_0.25"

# combine the wet and dry data sets:
dry.yrs <- rbind(post.dry, pre.dry)
msk <- sample.split( dry.yrs, SplitRatio = 3/4, group = NULL )

train <- dry.yrs[msk,]
test <- dry.yrs[!msk,]

# save training and testing for later:
saveRDS(train, "outputs/growth_model/basic_reg_dry_cohort_site_re/train.rds")
saveRDS(test, "outputs/growth_model/basic_reg_dry_cohort_site_re/test.rds")

cohort.model.dry.re <- jags.model(textConnection(cohort_model_dry_site_re), 
                    data = list(Y=log(dry.yrs$RWI), n=length(dry.yrs$RWI), DI.scaled = dry.yrs$DI.scaled, DBH.scaled = dry.yrs$DBH.scaled, cohort = as.numeric(dry.yrs$ageclass), S = unique(dry.yrs$ageclass),
                    plot = as.numeric(dry.yrs$site), ind = unique(dry.yrs$site),  np=length(test$RWI), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass), SP = unique(test$ageclass),
                    plot.p = as.numeric(test$site), ind.p = unique(test$site)), n.chains = 3, n.adapt = 100)

update(cohort.model.dry.re, 2000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(cohort.model.dry.re, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2", "sigma_beta3", "mu_beta1", "mu_beta2", "mu_beta3","Yp"), 
                    n.chains = 3, n.iter=10000, thin = 10)

summary(samp)
traceplot(samp)
gelman.diag(samp)



#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp[[1]]
 
 saveRDS(samps, "outputs/growth_model/basic_reg_dry_cohort_site_re/samps_full.rds")
 samps <-  readRDS( "outputs/growth_model/basic_reg_dry_cohort_site_re/samps_full.rds")
 Yp.samps    <- samps[,1:length(test$RWI)] 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,(length(test$RWI)+1):(length(test$RWI)+2)]
 beta2.samps <- samps[,(length(test$RWI)+3):(length(test$RWI)+4)]
 beta3.samps <- samps[,(length(test$RWI)+5):(length(test$RWI)+6)]
 mu_beta1.samps <- samps[,(length(test$RWI)+7):(length(test$RWI)+20)]
 mu_beta2.samps <- samps[,(length(test$RWI)+21):(length(test$RWI)+34)]
 mu_beta3.samps <- samps[,(length(test$RWI)+35):(length(test$RWI)+48)]
 sigma.samps <- samps[,(length(test$RWI)+49)]
 sigma_betas <- samps[,(length(test$RWI)+50):(length(test$RWI)+52)]

 
png("outputs/growth_model/basic_reg_dry_cohort_site_re/pred_vs_obs.png")
plot(colMeans(exp(Yp.samps)), test$RWI) 
abline(a = 0, b = 1, col = "red")
dev.off()

residual <- colMeans(exp(Yp.samps)) - test$RWI

hist(residual)


png("outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past")
hist(alpha.samps[,2], main = "alpha Modern")
#hist(alpha.samps[,3],  main = "alpha Past-Forest")
#hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta2.samps[,2], main = "beta2 Modern-Savanna")
#hist(beta2.samps[,3],  main = "beta2 Past-Forest")
#hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()





png("outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
#hist(beta3.samps[,3],  main = "beta3 Past-Forest")
#hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_mu_beta2s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta2.samps))){
  hist(mu_beta2.samps[,i], main = paste(colnames(mu_beta2.samps)[i]))
}
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_mu_beta3s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta3.samps[,i], main = paste(colnames(mu_beta3.samps)[i]))
}
dev.off()

png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_mu_beta1s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta1.samps))){
  hist(mu_beta1.samps[,i], main = paste(colnames(mu_beta1.samps)[i]))
}
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-", c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("Random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0(c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <-ggplot(b2.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.0075)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black(base_size = 18)+scale_fill_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))

b2.mean <- apply(as.matrix(b2[,1:2]), 2, mean)
b2.lower <- apply(as.matrix(b2[,1:2]), 2, function(x) quantile(x, probs = c(0.05)))
b2.upper <- apply(as.matrix(b2[,1:2]), 2, function(x) quantile(x, probs = c(0.95)))

## Combine both estimates
plot.dat.b2 <- data.frame(b2.mean, b2.lower, b2.upper)
plot.dat.b2$class <- row.names(plot.dat.b2)
plot.dat.b2$class <- factor(plot.dat.b2$class, levels = c("Past", "Modern"))
b2.dots <- ggplot(plot.dat.b2, aes(x = b2.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = b2.lower, xmax = b2.upper, size = 2,height = 0)+geom_point()+xlim(0 , 0.25)+theme_black(base_size = 18)+scale_color_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))+coord_flip()+theme(legend.position = "none")+xlab("Estimated Drought Sensitivity")

png(height = 5, width = 8, units = "in", res = 300, "outputs/growth_model/basic_reg_dry_cohort_site_re/drougt_beta_marginal_distn_bycohort.png")
plot_grid(b2.dots+xlim(0.05 , 0.3), b2.mplots+coord_flip()+xlim(0.05 , 0.3)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))
dev.off()

# difference between betas:
beta2.diff <- beta2.samps[,1] - beta2.samps[,2]

b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("DBH slope")



library(cowplot)
png(width = 5, height = 10, units = "in", res = 300, "outputs/growth_model/basic_reg_dry_cohort_site_re/param_marginal_distn_bycohort.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 beta3.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
 #mu_beta1.samps <- colMeans(mu_beta1.samps) 
 #mu_beta2.samps <- colMeans(mu_beta2.samps) 
 #mu_beta3.samps <- colMeans(mu_beta3.samps) 


# get posterior predictions:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2, site = as.numeric(unique(full.ghcn$site)))
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:



 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 
 
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

        
        alpha1.mn <- rnorm(1000, mu_beta1.samps[Xp[j,4]], mean(sigma_betas[,1]) ) # check the sigma betas
        beta2.mn <- rnorm(1000, mu_beta2.samps[Xp[j,4]], mean(sigma_betas[,2]) ) # check the sigma betas
        beta3.mn <- rnorm(1000, mu_beta3.samps[Xp[j,3]], mean(sigma_betas[,3]) ) # check the sigma betas
       
   mu <- alpha1.mn + beta2.mn*Xp[j,1] + beta2.mn*Xp[j,2]   # use
   
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   
   ypred[[j]]  <- mu
  # lines(density(y),col=2)
   
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)


Xp$MeanY <- exp(rowMeans(ypred.df))

Xp$cohort <- ifelse(Xp$cohort == 2, "Past",  
                       ifelse(Xp$cohort == 1, "Modern",NA))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1, MeanY, color = as.factor(site), shape = as.factor(cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(cohort))
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site))
dev.off()


png(height = 10, width = 10, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site) + as.factor(cohort))
dev.off()

```
# intercept only model (mean for d13C):
```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
d13C_intercept_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model for iWUE:
iWUE[i]   ~ dnorm(iwuefunc[i], inv.var) # where Yi is already log transformed

# function g()
iwuefunc[i] <- beta1[struct.cohort[i]]

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
}



# use normal hyperpriors for each hyperparamters 

mu_beta1 ~ dnorm(0, 0.1)


inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)



# Non-informative Prior for the inverse population variances

inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)


}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
Y.iwue <- d13$iWUE
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))


if(!"structure" %in% colnames(full.ghcn)){
full.ghcn <- merge(full.ghcn, structure, by = "site")
}
full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)
# read in VPD data and merge with full data:
full.prism <- read.csv("outputs/data/full_det_prism_rwi.csv")
full.ghcn <- merge(full.ghcn, full.prism[,c("year", "site", "ID", "VPDmax", "jja.VPDmax", "BAL", "jul.BAL", "jul.VPDmax")], by = c("year", "site", "ID"))
full.ghcn$jul.VPDmax.scaled <- as.numeric(scale(full.ghcn$jul.VPDmax))
full.ghcn$iWUE.scaled <- as.numeric(scale(full.ghcn$iWUE))
d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
n = length(full.ghcn$Cor.d13C.suess)


# split into testing and training:
library(caTools)
full.iso <- full.ghcn[!is.na(full.ghcn$iWUE) & !full.ghcn$site %in% "BON",]
#full.iso <- full.ghcn
iWUE.med<- full.iso %>% group_by(struct.cohort, struct.cohort.code) %>% summarise(iWUEmean = median(iWUE, na.rm =TRUE))
msk <- sample.split( full.iso, SplitRatio = 3/4, group = NULL )

train <- full.iso[msk,]
test <- full.iso[!msk,]

iwue_mean <- jags.model(textConnection(d13C_intercept_re), 
                    data = list(iWUE = full.iso$Cor.d13C.suess, n=length(full.iso$iWUE), struct.cohort = as.numeric(full.iso$struct.cohort.code), SF = unique(full.iso$struct.cohort.code)), n.chains = 3, n.adapt = 100)

update(iwue_mean, 1000); # Burnin for 1000 samples to start, then go higher later


iwue.mean.re <- coda.samples(iwue_mean, 
                     variable.names=c("beta1", "mu_beta1"), 
                    n.chains = 3, n.iter = 20000, thin = 15)

summary(iwue.mean.re )
plot(iwue.mean.re )

gelman.diag(iwue.mean.re )
acfplot(iwue.mean.re )

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- iwue.mean.re [[1]]
 saveRDS(samps, "outputs/growth_model/d13C_intercept_mode/samps.d13_nobon.rds")
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 #d13pred <- samps
 alpha.samps  <- samps[,1:4]



png("outputs/growth_model/d13C_intercept_mode/marginal_alphas_v3_iWUE.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")

dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0(c("Past-Forest", "Modern-Forest", "Past-Savanna", "Modern-Savanna")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+ylab("frequency")+xlab("iWUE")


ggplot(a.m, aes(variable, value, fill = variable))+geom_boxplot(alpha = 0.5)+theme_black()+ylab("frequency")+xlab("iWUE")

a <- data.frame(alpha.samps)
colnames(a) <- c(paste0(c(unique(full.iso$struct.cohort)[order(unique(full.iso$struct.cohort.code))])))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
a.mplots <-ggplot(a.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.5)+theme_bw()+xlab("Estimated mean D13C")+theme_black(base_size = 16)+scale_fill_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))

a.mean <- apply(as.matrix(a[,1:4]), 2, mean)
a.lower <- apply(as.matrix(a[,1:4]), 2, function(x) quantile(x, probs = c(0.025)))
a.upper <- apply(as.matrix(a[,1:4]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.a <- data.frame(a.mean, a.lower, a.upper)
plot.dat.a$class <- row.names(plot.dat.a)
plot.dat.a$class <- factor(plot.dat.a$class, levels = c("Past-Forest", "Past-Savanna", "Modern-Forest", "Modern-Savanna"))

a.dots <- ggplot(plot.dat.a, aes(x = a.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = a.lower, xmax = a.upper, size = 2,height = 0)+geom_point()+xlim(-26, -22)+theme_black(base_size = 16)+scale_color_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))+coord_flip()+theme(legend.position = "none")+xlab("Estimated Mean d13C")

png(height = 5, width = 12, units = "in",res = 300,"outputs/growth_model/d13C_intercept_mode/d13C_alpha_marginal_distn_bycohort.png")
plot_grid(a.dots, a.mplots+coord_flip()+ xlim(-26, -22)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()), rel_widths = c(1,0.75))
dev.off()

library(cowplot)
png(width = 7, height = 3, units = "in", res = 300, "outputs/growth_model/iWUE_intercept_mod/param_marginal_distn_bycohort_struct_v3_iwue_random_slopes.png")
plot_grid(alpha.mplots, ncol = 1)
dev.off()

plot.dat.a$ageclass <- ifelse(plot.dat.a$class %in% c("Past-Savanna", "Past-Forest"), "Past", "Modern")
plot.dat.a$ageclass <- factor(plot.dat.a$ageclass, levels = c("Past", "Modern"))

plot.dat.a$forestclass <- ifelse(plot.dat.a$class %in% c("Past-Savanna", "Modern-Savanna"), "Savanna", "Forest")

a.dots.2 <- ggplot(plot.dat.a, aes(x = a.mean, y = ageclass, color = ageclass, size = 2))+geom_errorbarh( xmin = a.lower, xmax = a.upper, size = 2,height = 0)+geom_point()+xlim(-26, -22)+theme_black(base_size = 18)+scale_color_manual(values = c("Past"='blue',
"Modern"='red'))+coord_flip()+theme(legend.position = "none", axis.text.x = element_blank())+xlab(expression(paste("Estimated " ,delta^{13}, "C (\u2030)")))+facet_wrap(~forestclass)

png(width = 5, height = 4, units = "in", res = 300, "outputs/growth_model/iWUE_intercept_mod/param_marginal_distn_bycohort_struct_v3_d13_random_slopes.png")
a.dots.2
dev.off()
```



# intercept only model (mean for iWUE):



```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
iWUE_intercept_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model for iWUE:
iWUE[i]   ~ dnorm(iwuefunc[i], inv.var) # where Yi is already log transformed

# function g()
iwuefunc[i] <- beta1[struct.cohort[i]]

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
}



# use normal hyperpriors for each hyperparamters 

mu_beta1 ~ dnorm(0, 0.1)


inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)



# Non-informative Prior for the inverse population variances

inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)


}"


# read in the d13 data, if it doesnt exist already

if(!exists("d13")){
d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
Y.iwue <- d13$iWUE
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)

#need to define site level structures:

if(!"structure" %in% colnames(full.ghcn)){
  structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))
full.ghcn <- merge(full.ghcn, structure, by = "site")
}




#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)
# read in VPD data and merge with full data:
full.prism <- read.csv("outputs/data/full_det_prism_rwi.csv")
full.ghcn <- merge(full.ghcn, full.prism[,c("year", "site", "ID", "VPDmax", "jja.VPDmax", "BAL", "jul.BAL", "jul.VPDmax")], by = c("year", "site", "ID"))
full.ghcn$jul.VPDmax.scaled <- as.numeric(scale(full.ghcn$jul.VPDmax))
full.ghcn$iWUE.scaled <- as.numeric(scale(full.ghcn$iWUE))
d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
n = length(full.ghcn$Cor.d13C.suess)


# split into testing and training:
library(caTools)
full.iso <- full.ghcn[!is.na(full.ghcn$iWUE) & !full.ghcn$site %in% "BON",]
#full.iso <- full.ghcn
iWUE.med<- full.iso %>% group_by(struct.cohort, struct.cohort.code) %>% summarise(iWUEmean = median(iWUE, na.rm =TRUE))
}


msk <- sample.split( full.iso, SplitRatio = 3/4, group = NULL )

train <- full.iso[msk,]
test <- full.iso[!msk,]

iwue_mean <- jags.model(textConnection(iWUE_intercept_re), 
                    data = list(iWUE = full.iso$iWUE, n=length(full.iso$iWUE), struct.cohort = as.numeric(full.iso$struct.cohort.code), SF = unique(full.iso$struct.cohort.code)), n.chains = 3, n.adapt = 100)

update(iwue_mean, 1000); # Burnin for 1000 samples to start, then go higher later


iwue.mean.re <- coda.samples(iwue_mean, 
                     variable.names=c("beta1", "mu_beta1"), 
                    n.chains = 3, n.iter = 20000, thin = 15)

summary(iwue.mean.re )
plot(iwue.mean.re )

gelman.diag(iwue.mean.re )
acfplot(iwue.mean.re )

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- iwue.mean.re [[1]]
 saveRDS(samps, "outputs/growth_model/iWUE_intercept_mod/samps.d13_nobon.rds")
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 #d13pred <- samps
 alpha.samps  <- samps[,1:4]



png("outputs/growth_model/iWUE_intercept_mod/marginal_alphas_v3_iWUE.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")

dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0(c("Past-Forest", "Modern-Forest", "Past-Savanna", "Modern-Savanna")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+ylab("frequency")+xlab("iWUE")


ggplot(a.m, aes(variable, value, fill = variable))+geom_boxplot(alpha = 0.5)+theme_black()+ylab("frequency")+xlab("iWUE")

a <- data.frame(alpha.samps)
colnames(a) <- c(paste0(c(unique(full.iso$struct.cohort)[order(unique(full.iso$struct.cohort.code))])))

a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
a.mplots <-ggplot(a.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.5)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black(base_size = 16)+scale_fill_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))

a.mean <- apply(as.matrix(a[,1:4]), 2, mean)
a.lower <- apply(as.matrix(a[,1:4]), 2, function(x) quantile(x, probs = c(0.025)))
a.upper <- apply(as.matrix(a[,1:4]), 2, function(x) quantile(x, probs = c(0.975)))

## Combine both estimates
plot.dat.a <- data.frame(a.mean, a.lower, a.upper)
plot.dat.a$class <- row.names(plot.dat.a)
plot.dat.a$class <- factor(plot.dat.a$class, levels = c("Past-Forest", "Past-Savanna", "Modern-Forest", "Modern-Savanna"))

a.dots <- ggplot(plot.dat.a, aes(x = a.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = a.lower, xmax = a.upper, size = 2,height = 0)+geom_point()+xlim(100, 160)+theme_black(base_size = 16)+scale_color_manual(values = c("Past-Savanna"='#a6611a',
"Modern-Savanna"='#dfc27d',
"Modern-Forest"='#c7eae5',
"Past-Forest"='#018571'))+coord_flip()+theme(legend.position = "none")+xlab("Estimated Drought Sensitivity")

png(height = 5, width = 12, units = "in",res = 300,"outputs/growth_model/iWUE_intercept_mod/iwue_alpha_marginal_distn_bycohort.png")
plot_grid(a.dots, a.mplots+coord_flip()+ xlim(100, 160)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()), rel_widths = c(1,0.75))
dev.off()

library(cowplot)
png(width = 7, height = 3, units = "in", res = 300, "outputs/growth_model/iWUE_intercept_mod/param_marginal_distn_bycohort_struct_v3_iwue_random_slopes.png")
plot_grid(alpha.mplots, ncol = 1)
dev.off()


plot.dat.a$ageclass <- ifelse(plot.dat.a$class %in% c("Past-Savanna", "Past-Forest"), "Past", "Modern")
plot.dat.a$ageclass <- factor(plot.dat.a$ageclass, levels = c("Past", "Modern"))
plot.dat.a$forestclass <- ifelse(plot.dat.a$class %in% c("Past-Savanna", "Modern-Savanna"), "Savanna", "Forest")


a.dots.2 <- ggplot(plot.dat.a, aes(x = a.mean, y = ageclass, color = ageclass, size = 2))+geom_errorbarh( xmin = a.lower, xmax = a.upper, size = 2,height = 0)+geom_point()+xlim(100, 160)+theme_black(base_size = 18)+scale_color_manual(values = c("Past"='blue',
"Modern"='red'))+coord_flip()+theme(legend.position = "none", axis.title.x = element_blank())+xlab("iWUE")+facet_wrap(~forestclass)

png(width = 5, height = 4, units = "in", res = 300, "outputs/growth_model/iWUE_intercept_mod/param_marginal_distn_bycohort_struct_v3_iwue_random_slopes.png")
a.dots.2
dev.off()

#predict the 
# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues




```





# adding a prediction for stable isotopes (d13C) from tree growth predictions
```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
d13_model_structure_x_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model for growth:
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1 + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i]+ beta4[struct.cohort[i]]*jul.VPDmax[i] + beta5[struct.cohort[i]]*iWUE[i] # use Drought index as a scaled variable 

# if there is d13 data, then use Y[i] to predict
#if(d13index[i]){
 # process model for d13C:
 #Y[i]   ~ dnorm(d13func[i], inv.var13) # where Yi is already log transformed
 #d13func[i] <- beta1 + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i] #+ beta4[struct.cohort[i]]*RWI[i] + beta5[struct.cohort[i]]*jul.VPDmax[i]
#}


#res[i] <- Y[i] - gfunc[i]   
#emp.new[i] ~ dnorm(gfunc[i], sigma)
#res.new[i] <- emp.new[i] - gfunc[i]
}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
#beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
# if we assume WUE is known for each group:
#mu_beta2[s] <- gamma1 * exp(-v*iWUE[s])
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
beta4[s] ~ dnorm(mu_beta4, inv_beta4)
beta5[s] ~ dnorm(mu_beta5, inv_beta5)
}


#gamma1 ~ dgamma(0.001, 0.001)
#v ~ dgamma(0.001, 0.001)

# model for stable isotopes:
#for(d in 1:n.d13){

  # process model for growth:
 # Y.d13[d]   ~ dnorm(gfuncd13[d], inv.var) # Model Yi using estimated parameter distributions 

  # function g()
  #gfuncd13[d] <- beta1[struct.cohort.d13[d]] + beta2[struct.cohort.d13[d]]*DI.scaled.d13[d] +         #  beta3[struct.cohort.d13[d]]*DBH.scaled.d13[d]   # use Drought index as a scaled variable 

 # process model for d13C:
 #d13[d]   ~ dnorm(d13func[d], inv.var13) # where Yi is already log transformed
 #d13func[d] <- beta.d131 + beta.d132*Y[d]

#}



# use normal hyperpriors for each hyperparamters 
beta1 ~ dnorm(0, 0.01)
#mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)
mu_beta4 ~ dunif(-2, 2)
mu_beta5 ~ dunif(-2, 2)
#beta.d131 ~ dnorm(0, 2)
#beta.d132 ~ dnorm(0,2)

#inv_beta1   ~ dgamma(0.01, 0.01)
#sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)
inv_beta4   ~ dgamma(0.01, 0.01)
sigma_beta4 <- 1/sqrt(inv_beta4)
inv_beta5   ~ dgamma(0.01, 0.01)
sigma_beta5 <- 1/sqrt(inv_beta5)

#inv.var13 ~ dgamma(0.01, 0.01)
#sigma_13 <- 1/sqrt(inv.var13)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)






}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
Y.iwue <- d13$iWUE
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)
# read in VPD data and merge with full data:
full.prism <- read.csv("outputs/data/full_det_prism_rwi.csv")
full.ghcn <- merge(full.ghcn, full.prism[,c("year", "site", "ID", "VPDmax", "jja.VPDmax", "BAL", "jul.BAL", "jul.VPDmax")], by = c("year", "site", "ID"))
full.ghcn$jul.VPDmax.scaled <- as.numeric(scale(full.ghcn$jul.VPDmax))
full.ghcn$iWUE.scaled <- as.numeric(scale(full.ghcn$iWUE))
d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
n = length(full.ghcn$Cor.d13C.suess)


# split into testing and training:
library(caTools)
full.iso <- full.ghcn[!is.na(full.ghcn$iWUE),]
#full.iso <- full.ghcn
iWUE.med<- full.iso %>% group_by(struct.cohort, struct.cohort.code) %>% summarise(iWUEmean = median(iWUE, na.rm =TRUE))
msk <- sample.split( full.iso, SplitRatio = 3/4, group = NULL )

train <- full.iso[msk,]
test <- full.iso[!msk,]

d13.model.by_structure_x_cohort <- jags.model(textConnection(d13_model_structure_x_cohort_re), 
                    data = list(Y = full.iso$RWI, n=length(full.iso$RWI), DI.scaled = full.iso$DI.scaled, DBH.scaled = full.iso$DBH.scaled, jul.VPDmax = full.iso$jul.VPDmax.scaled, iWUE = full.iso$iWUE.scaled, struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(full.iso$struct.cohort.code)), n.chains = 3, n.adapt = 100)

update(d13.model.by_structure_x_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


d13.structure.cohort.re <- coda.samples(d13.model.by_structure_x_cohort, 
                     variable.names=c("beta1", "beta2","beta3", "beta4", "beta5","sigma_beta2","sigma_beta3", "sigma_beta4","sigma_beta5"), 
                    n.chains = 3, n.iter = 200000, thin = 15)

summary(d13.structure.cohort.re)
plot(d13.structure.cohort.re)

gelman.diag(d13.structure.cohort.re)
acfplot(d13.structure.cohort.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- d13.structure.cohort.re[[1]]
 saveRDS(samps, "outputs/growth_model/d13_reg_struct_x_cohort/samps.wue.rds")
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 #d13pred <- samps
 alpha.samps  <- samps[,1]
 beta2.samps <- samps[,2:5]
 beta3.samps <- samps[,6:9]
 beta4.samps <- samps[,10:13]
 beta5.samps <- samps[,14:17]
 sigma.samps <- samps[,16]
 #sigma13.samps <- samps[,15]
 sigma_betas <- samps[,17:21]
 d13pred <- samps[,18:8228]
 #betad131.samps <- samps[,1]
 #betad132.samps <- samps[,2]

# plot marginal distributions of each parameter:
png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_d13_sigmas_v3_iWUE.png")
par(mfrow=c(2,2))
#hist(betad131.samps, main = "alpha d13")
#hist(betad132.samps, main = "beta d13")
hist(sigma.samps, main = "sigma")
dev.off()

png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_alphas_v3_iWUE.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_beta1s_v3_IWUE.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta3.samps[,2], main = "beta2 Modern-Savanna")
hist(beta4.samps[,3],  main = "beta2 Past-Forest")
hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_beta2s_v3_iwue.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
hist(beta3.samps[,3],  main = "beta3 Past-Forest")
hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(full.ghcn$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c(unique(full.ghcn$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(full.ghcn$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()

b4 <- data.frame(beta4.samps)
colnames(b4) <- c(paste0("beta3-",c(unique(full.ghcn$struct.cohort))))
b4$num <- rownames(b4)
b4.m <- melt(b4, id.vars=c("num"))
b4.mplots <- ggplot(b4.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()

b5 <- data.frame(beta5.samps)
colnames(b5) <- c(paste0("beta5-",c(unique(full.ghcn$struct.cohort))))
b5$num <- rownames(b5)
b5.m <- melt(b5, id.vars=c("num"))
b5.mplots <- ggplot(b5.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()



library(cowplot)
png(width = 4, height = 8, units = "in", res = 300, "outputs/growth_model/d13_reg_struct_x_cohort/param_marginal_distn_bycohort_struct_v3_iwue_random_slopes.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, b4.mplots, b5.mplots, ncol = 1)
dev.off()


#predict the 
# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues

pval113.d <- mean(d13pred.df > d13$Cor.d13C.suess) 


Xp$MeanY <- exp(rowMeans(ypred.df))
Xp$Meand13<- rowMeans(d13pred.df)# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()






#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2, Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted d13")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = Meand13))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()



```

```{r}
d13only_model_structure_x_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){

 d13[i]   ~ dnorm(d13func[i], inv.var13) # where Yi is already log transformed
 d13func[i] <- beta1[struct.cohort[i]] + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i] + beta4[struct.cohort[i]]*VPD.max.scaled[i]

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
beta4[s] ~ dnorm(mu_beta4, inv_beta4)
}




# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)
mu_beta4 ~ dunif(-2, 2)
mu_beta5 ~ dunif(-2, 2)
beta.d131 ~ dnorm(0, 2)
beta.d132 ~ dnorm(0,2)

inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)
inv_beta4   ~ dgamma(0.01, 0.01)
sigma_beta4 <- 1/sqrt(inv_beta4)
inv_beta5   ~ dgamma(0.01, 0.01)
sigma_beta5 <- 1/sqrt(inv_beta5)

# Non-informative Prior for the inverse population variances
inv.var13 ~ dgamma(0.01, 0.01)
sigma_13 <- 1/sqrt(inv.var13)


# Prediction using testing data
for(i in 1:np){

 d13.p[i]   ~ dnorm(d13func.p[i], inv.var13) # where Yi is already log transformed
 d13func.p[i] <- beta1[struct.cohort.p[i]] + beta2[struct.cohort.p[i]]*DI.scaled.p[i] + beta3[struct.cohort.p[i]]*DBH.scaled.p[i] + beta4[struct.cohort.p[i]]*VPD.max.scaled.p[i]

}

}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)

d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)


d13.model.only.by_structure_x_cohort <- jags.model(textConnection(d13only_model_structure_x_cohort_re), 
                    data = list( n=length(train$DI.scaled), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(train$struct.cohort.code), d13 = train$iWUE, VPD.max.scaled= train$jul.VPDmax.scaled, np=length(test$DI.scaled), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, struct.cohort.p = as.numeric(test$struct.cohort.code),  VPD.max.scaled.p= test$jul.VPDmax.scaled), n.chains = 3, n.adapt = 100)

update(d13.model.only.by_structure_x_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


d13.model.only.by_structure_x_cohort <- coda.samples(d13.model.only.by_structure_x_cohort, 
                     variable.names=c("beta1", "beta2","beta3","beta4", "sigma_beta1", "sigma_beta2","sigma_beta3", "sigma_beta4", "d13.p"), 
                    n.chains = 3, n.iter = 20000, thin = 10)

summary(d13.model.only.by_structure_x_cohort)
plot(d13.model.only.by_structure_x_cohort)

gelman.diag(d13.model.only.by_structure_x_cohort)
acfplot(d13.model.only.by_structure_x_cohort)

#Extract the samples for each parameter for a basic exploration of effects

samps       <- d13.model.only.by_structure_x_cohort[[1]]
saveRDS(samps,"outputs/growth_model/wue_reg_struct_x_cohort/samps.rds")
plot(d13.model.only.by_structure_x_cohort)

 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,1:4]
 beta2.samps <- samps[,5:8]
 beta3.samps <- samps[,9:12]
 beta4.samps <- samps[,13:16]
 iWUEpred.samps <- samps[,17:2801]
 #sigma13.samps <- samps[,15]
 #sigma_betas <- samps[,16:18]

 #betad131.samps <- samps[,1]
 #betad132.samps <- samps[,2]


png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_alphas_v3.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta1s_v3.png")
par(mfrow=c(3,2))
hist(beta1.samps[,1], main = "beta2 Past-Savanna")
hist(beta1.samps[,2], main = "beta2 Modern-Savanna")
hist(beta1.samps[,3],  main = "beta2 Past-Forest")
hist(beta1.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta2s_v3.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta3 Past-Savanna")
hist(beta2.samps[,2], main = "beta3 Modern-Savanna")
hist(beta2.samps[,3],  main = "beta3 Past-Forest")
hist(beta2.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(train$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()++xlab("Intercepts for iWUE")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c(unique(train$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Summer Drought")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(train$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Tree DBH")

b4 <- data.frame(beta4.samps)
colnames(b4) <- c(paste0("beta4-",c(unique(train$struct.cohort))))
b4$num <- rownames(b4)
b4.m <- melt(b4, id.vars=c("num"))
b4.mplots <- ggplot(b4.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of July VPD")


library(cowplot)
png(width = 4, height = 8, units = "in", res = 300, "outputs/growth_model/wue_reg_struct_x_cohort/param_marginal_distn_bycohort_struct_v3.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots,b4.mplots, ncol = 1)
dev.off()


# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 VPDprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,VPDprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues

pval113.d <- mean(d13pred.df > d13$Cor.d13C.suess) 


Xp$MeanY <- exp(rowMeans(ypred.df))
Xp$Meand13<- rowMeans(d13pred.df)# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()






#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2, Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted d13")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = Meand13))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()



```
# cohort only model:

```{r}
d13only_model_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){

 d13[i]   ~ dnorm(d13func[i], inv.var) # where Yi is already log transformed
 d13func[i] <- beta1[cohort[i]]

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
}


# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)


inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)


# Non-informative Prior for the inverse population variances
inv.var ~ dgamma(0.01, 0.01)
sigma <- 1/sqrt(inv.var)


# Prediction using testing data
for(i in 1:np){

 d13.p[i]   ~ dnorm(d13func.p[i], inv.var) # where Yi is already log transformed
 d13func.p[i] <- beta1[cohort.p[i]] 

}

}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)


d13.model.only.by_cohort <- jags.model(textConnection(d13only_model_cohort_re), 
                    data = list( n=length(full.iso$DI.scaled), cohort = as.numeric(full.iso$ageclass), SF = unique(full.iso$ageclass), d13 = full.iso$Cor.d13C.suess,  np=length(test$DI.scaled),  cohort.p = as.numeric(test$ageclass)), n.chains = 3, n.adapt = 100)

update(d13.model.only.by_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


d13.model.only.by_structure_x_cohort <- coda.samples(d13.model.only.by_cohort, 
                     variable.names=c("beta1","sigma", "d13.p"), 
                    n.chains = 3, n.iter = 20000, thin = 10)

summary(d13.model.only.by_structure_x_cohort)
plot(d13.model.only.by_structure_x_cohort)

gelman.diag(d13.model.only.by_structure_x_cohort)
acfplot(d13.model.only.by_structure_x_cohort)

#Extract the samples for each parameter for a basic exploration of effects

samps       <- d13.model.only.by_structure_x_cohort[[1]]
saveRDS(samps,"outputs/growth_model/d13_reg_cohort/samps.rds")
plot(d13.model.only.by_structure_x_cohort)

 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 d13.samps <- samps[,1:length(test$site)]
 alpha.samps  <- samps[,1:2]
 


png("outputs/growth_model/d13_reg_cohort/marginal_alphas_v3.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")

dev.off()




# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c("Modern", "Past")
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Intercepts for iWUE")


a.mplots <-ggplot(a.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.05)+theme_bw()+xlab("Estimated Drought Sensitivity")+theme_black(base_size = 18)+scale_fill_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))

a.mean <- apply(as.matrix(a[,1:2]), 2, mean)
a.lower <- apply(as.matrix(a[,1:2]), 2, function(x) quantile(x, probs = c(0.05)))
a.upper <- apply(as.matrix(a[,1:2]), 2, function(x) quantile(x, probs = c(0.95)))

## Combine both estimates
plot.dat.a <- data.frame(a.mean, a.lower, a.upper)
plot.dat.a$class <- row.names(plot.dat.a)
plot.dat.a$class <- factor(plot.dat.a$class, levels = c("Past", "Modern"))
a.dots <- ggplot(plot.dat.a, aes(x = a.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = a.lower, xmax = a.upper, size = 2,height = 0)+geom_point()+xlim(-26, -22)+theme_black(base_size = 18)+scale_color_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))+coord_flip()+theme(legend.position = "none")+xlab("d13C")

png(height = 5, width = 8, units = "in", res = 300, "outputs/growth_model/d13_reg_cohort/drougt_beta_marginal_distn_bycohort.png")
plot_grid(a.dots+xlim(-26,-22), a.mplots+coord_flip()+xlim(-26,-22)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))
dev.off()


```
```{r}
iwueonly_model_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){

 d13[i]   ~ dnorm(d13func[i], inv.var) # where Yi is already log transformed
 d13func[i] <- beta1[cohort[i]]

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
}


# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)


inv_beta1   ~ dgamma(0.1, 0.1)
sigma_beta1 <- 1/sqrt(inv_beta1)


# Non-informative Prior for the inverse population variances
inv.var ~ dgamma(0.01, 0.01)
sigma <- 1/sqrt(inv.var)


# Prediction using testing data
for(i in 1:np){

 d13.p[i]   ~ dnorm(d13func.p[i], inv.var) # where Yi is already log transformed
 d13func.p[i] <- beta1[cohort.p[i]] 

}

}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)


iwue.model.only.by_cohort <- jags.model(textConnection(iwueonly_model_cohort_re), 
                    data = list( n=length(full.iso$DI.scaled), cohort = as.numeric(full.iso$ageclass), SF = unique(full.iso$ageclass), d13 = full.iso$iWUE,  np=length(test$DI.scaled),  cohort.p = as.numeric(test$ageclass)), n.chains = 3, n.adapt = 100)

update(iwue.model.only.by_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


iwue.model.only <- coda.samples(iwue.model.only.by_cohort, 
                     variable.names=c("beta1","sigma", "d13.p"), 
                    n.chains = 3, n.iter = 20000, thin = 10)

summary(iwue.model.only )
plot(iwue.model.only )

gelman.diag(iwue.model.only )
acfplot(iwue.model.only )

#Extract the samples for each parameter for a basic exploration of effects

samps       <- iwue.model.only[[1]]
saveRDS(samps,"outputs/growth_model/iwue_reg_cohort/samps.rds")
plot(d13.model.only.by_structure_x_cohort)

 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 d13.samps <- samps[,1:length(test$site)]
 alpha.samps  <- samps[,1:2]
 


png("outputs/growth_model/iwue_reg_cohort/marginal_alphas_v3.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")

dev.off()




# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c("Modern", "Past")
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Estimated iWUE")


a.mplots <-ggplot(a.m, aes(value,1, fill = variable))+stat_density_ridges(alpha = 0.5, quantile_lines = TRUE, quantiles = c(0.025, 0.975), bandwidth  = 0.5)+theme_bw()+xlab("Estimated iWUE")+theme_black(base_size = 18)+scale_fill_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))

a.mean <- apply(as.matrix(a[,1:2]), 2, mean)
a.lower <- apply(as.matrix(a[,1:2]), 2, function(x) quantile(x, probs = c(0.05)))
a.upper <- apply(as.matrix(a[,1:2]), 2, function(x) quantile(x, probs = c(0.95)))

## Combine both estimates
plot.dat.a <- data.frame(a.mean, a.lower, a.upper)
plot.dat.a$class <- row.names(plot.dat.a)
plot.dat.a$class <- factor(plot.dat.a$class, levels = c("Past", "Modern"))
a.dots <- ggplot(plot.dat.a, aes(x = a.mean, y = class, color = class, size = 2))+geom_errorbarh( xmin = a.lower, xmax = a.upper, size = 2,height = 0)+geom_point()+xlim(115, 160)+theme_black(base_size = 18)+scale_color_manual(values = c("Past"='#d73027',
"Modern"='#4575b4'))+coord_flip()+theme(legend.position = "none")+xlab("iWUE")

png(height = 5, width = 8, units = "in", res = 300, "outputs/growth_model/iwue_reg_cohort/drougt_beta_marginal_distn_bycohort.png")
plot_grid(a.dots+xlim(115, 160), a.mplots+coord_flip()+xlim(115, 160)+ylab("frequency")+theme(axis.title.y = element_blank(), axis.ticks.y = element_blank(), axis.text.y = element_blank()))
dev.off()


```


# model growth and response to climate as a function of WUE:

```{r}
wue_model_structure_x_cohort_re_plot_effects <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){

 iWUE[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed
 gfunc[i] <- beta1[struct.cohort[i]] + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i] + beta4[struct.cohort[i]]*VPD.max.scaled[i] 

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
beta4[s] ~ dnorm(mu_beta4, inv_beta4)

#mu_beta2[s] <- gam*exp(v*iWUE.dist[s])
#iWUE.dist[s] ~ dnorm(iWUE.data[s], sigma.WUE[s])

#gam ~ dnorm(0, 0.01)
#v ~ dnorm(0, 0.01)

}


#gam ~ dnorm(0, 0.01)
#v ~ dnorm(0, 0.01)

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)
mu_beta4 ~ dunif(-2, 2)
mu_beta5 ~ dunif(-2, 2)


inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)
inv_beta4   ~ dgamma(0.01, 0.01)
sigma_beta4 <- 1/sqrt(inv_beta4)
inv_beta5   ~ dgamma(0.01, 0.01)
sigma_beta5 <- 1/sqrt(inv_beta5)

# Non-informative Prior for the inverse population variances
inv.var ~ dgamma(0.01, 0.01)
sigma <- 1/sqrt(inv.var)




}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)


iwue.df<- full.ghcn %>% group_by(struct.cohort, struct.cohort.code) %>% summarise(iWUE.dat = median(iWUE, na.rm=TRUE), iwue.sd = sd(iWUE, na.rm = TRUE))

train.df <- merge(iwue.df, train, by = c("struct.cohort", "struct.cohort.code"))
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)

d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)


d13.model.only.by_structure_x_cohort <- jags.model(textConnection(growth_wue_model_structure_x_cohort_re), 
                    data = list( n=length(train$DI.scaled), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(train$struct.cohort.code), Y = log(train$RWI), VPD.max.scaled= train$jul.VPDmax.scaled, iWUE.data = train.df$iWUE.dat, sigma.WUE = train.df$iwue.sd ), n.chains = 3, n.adapt = 100)

update(growth_wue_model_structure_x_cohort_re, 100); # Burnin for 1000 samples to start, then go higher later


d13.model.only.by_structure_x_cohort <- coda.samples(growth_wue_model_structure_x_cohort_re, 
                     variable.names=c("beta1", "beta2","beta3","beta4", "sigma_beta1", "sigma_beta2","sigma_beta3", "sigma_beta4", "v", "gam", "mu_beta2"), 
                    n.chains = 3, n.iter = 20000, thin = 10)

summary(d13.model.only.by_structure_x_cohort)
plot(d13.model.only.by_structure_x_cohort)

gelman.diag(d13.model.only.by_structure_x_cohort)
acfplot(d13.model.only.by_structure_x_cohort)

#Extract the samples for each parameter for a basic exploration of effects

samps       <- d13.model.only.by_structure_x_cohort[[1]]
saveRDS(samps,"outputs/growth_model/wue_reg_struct_x_cohort/samps.rds")
plot(d13.model.only.by_structure_x_cohort)

 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,1:4]
 beta2.samps <- samps[,5:8]
 beta3.samps <- samps[,9:12]
 beta4.samps <- samps[,13:16]
 sigma.samps <- samps[,17:20]
 #sigma13.samps <- samps[,15]
 #sigma_betas <- samps[,16:18]

 #betad131.samps <- samps[,1]
 #betad132.samps <- samps[,2]


png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_alphas_v3.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta1s_v3.png")
par(mfrow=c(3,2))
hist(beta1.samps[,1], main = "beta2 Past-Savanna")
hist(beta1.samps[,2], main = "beta2 Modern-Savanna")
hist(beta1.samps[,3],  main = "beta2 Past-Forest")
hist(beta1.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta2s_v3.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta3 Past-Savanna")
hist(beta2.samps[,2], main = "beta3 Modern-Savanna")
hist(beta2.samps[,3],  main = "beta3 Past-Forest")
hist(beta2.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(train$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()++xlab("Intercepts for iWUE")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c(unique(train$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Summer Drought")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(train$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Tree DBH")

b4 <- data.frame(beta4.samps)
colnames(b4) <- c(paste0("beta4-",c(unique(train$struct.cohort))))
b4$num <- rownames(b4)
b4.m <- melt(b4, id.vars=c("num"))
b4.mplots <- ggplot(b4.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of July VPD")


library(cowplot)
png(width = 4, height = 8, units = "in", res = 300, "outputs/growth_model/wue_reg_struct_x_cohort/param_marginal_distn_bycohort_struct_v3.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots,b4.mplots, ncol = 1)
dev.off()


# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues

pval113.d <- mean(d13pred.df > d13$Cor.d13C.suess) 


Xp$MeanY <- exp(rowMeans(ypred.df))
Xp$Meand13<- rowMeans(d13pred.df)# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()






#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2, Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted d13")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = Meand13))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()



```





## Bayesian heirarchical liner regression where alpha and beta coeffiencents are specific to savanna and forest cover:
# this model explores whether stand structure (savanna or forest) has an impact on the slope and intercept response to climate

```{r}


Y <- as.vector(log(full.ghcn$RWI)) 
# create table of savanna and forest

for.df <- data.frame(site = unique(full.ghcn$site), 
           fortype = c("forest", "savanna", "forest" ,"forest", "savanna", "forest", "savanna", "savanna", "forest", "savanna", "savanna", "savanna", "savanna", "savanna", "forest", "savanna"))

full.ghcn <- merge(full.ghcn, for.df, by = "site")
full.ghcn$fornum <- ifelse(full.ghcn$fortype %in% "forest", 1, 2)
# standardise predictor variables to have mean 0 and sd = 1
#DI.scaled = scale(full.ghcn$JJA.pdsi, center= TRUE, scale=TRUE)
#T.scaled = scale(full.ghcn$JUNTmax, center= TRUE, scale=TRUE)
#full.ghcn$DI.scaled = as.vector(scale(full.ghcn$JJA.pdsi, center = TRUE, scale = TRUE))
ggplot(full.ghcn, aes(DI.scaled,log(RWI), color = ageclass))+geom_point(size = 0.2)+geom_smooth(method = "lm")+facet_wrap(~fortype)


png(height= 5, width = 7, units = "in", res = 300, "outputs/two_age_class_logbai_past_mod.png")
ggplot(full.ghcn[full.ghcn$RWI <= 6200, ], aes(JJA.pdsi, log(RWI), color = ageclass))+geom_point(size = 0.02)+geom_smooth(method = "lm")+facet_wrap(~fortype)
dev.off()

#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH.x, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode

summary(lm(Y ~ log(DBH)))

summary(lm(Y ~ log(DBH) + log((pdsi + 10)/20) + log(JunTmax)  ))
summary(lmer(Y ~ DI.scaled+ (DI.scaled|ageclass)))
# population model for the response of each BAI to each year of climate:
population_model_age_class <- "model{

# for each type of stand structure:



# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[fortype[i]], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- alpha[fortype[i]]+ beta2[fortype[i]] *DI.scaled[i]    # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
alpha[s] ~ dnorm(mu_alpha, inv_alpha)
beta2[s] ~ dnorm(mu_beta, inv_beta)
}

# use normal hyperpriors for each hyperparamters 
mu_alpha ~ dunif(-2, 2)
mu_beta ~ dunif(-2, 2)

inv_alpha   ~ dgamma(0.0001, 0.0001)
sigma_alpha <- 1/sqrt(inv_alpha)
inv_beta   ~ dgamma(0.001, 0.001)
sigma_beta <- 1/sqrt(inv_beta)



# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)

}"

lmer.age <- lmer(Y ~ DI.scaled + (1|ageclass == 1))
ranef(lmer.age)
ggplot(full.ghcn[full.ghcn$RWI < 5500, ], aes(DBH.x, RWI , color = ageclass))+geom_point(size = 0.02)+stat_smooth(method = "lm")
indiv <- lmer(log(RWI) ~ DI.scaled + (DI.scaled|ID), data = full.ghcn)

initsList

# now 
reg.model.by_s <- jags.model(textConnection(population_model_age_class), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, fortype = ageclass, S = unique(ageclass)), n.chains = 3, n.adapt = 100)

update(reg.model.by_s, 40000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(reg.model.by_s, 
                     variable.names=c("beta", "beta2","alpha","sigma", "sigma_alpha"), 
                    n.chains = 3, n.iter=20000, thin = 10)

summary(samp)
gelman.diag(samp)
traceplot(samp)
plot(samp)

# quick check to see how params compare to OLS 
#summary(lm(Y ~ full.ghcn$DI.scaled))

# plot mcmc + the parameter distn
plot(samp)
gelman.diag(samp)
acfplot(samp, aspect = 2)


gelman.plot(samp)
# evaluate MCMC convergence:


# save a data frame with beta2 sensitivity and the 
samp.basic.reg.df <- summary(samp)
  
samp.basic.df.sum<- data.frame(mean = samp.df$statistics[2,"Mean"], 
           ci.low = samp.df$quantiles[2,"2.5%"], 
           ci.high = samp.df$quantiles[2,"97.5%"])
  



# lets do the model where stand only affects the slope and not the intercept, perhaps this will help it converge:

population_model_stand <- "model{

# for each type of stand structure:



# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[fortype[i]], inv.var) # where Yi is already log transformed


# function g()
gfunc[i] <- alpha +  beta[fortype[i]]*DI.scaled[i] # use Drought index as a scaled variable 
}

# Assume normal priors for betas, but generate a beta + alpha for each forest type s
for(s in 1:length(S)){

beta[s] ~ dnorm(mu_beta, inv_beta)
}

# use normal hyperpriors for each hyperparamters 
#mu_alpha ~ dnorm(0, 0.1)
mu_beta ~ dnorm(0, 0.1)

#inv_alpha   ~ dgamma(0.001, 0.001)
#sigma_alpha <- 1/sqrt(inv_alpha)
inv_beta   ~ dgamma(0.001, 0.001)
sigma_beta <- 1/sqrt(inv_beta)



# Non-informative Prior for the inverse population variances
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)
alpha ~ dnorm(0, 0.1)

}"

# now 
reg.model.by_s <- jags.model(textConnection(population_model_stand), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, fortype =    full.ghcn$fornum, S = unique(full.ghcn$fornum)))

update(reg.model.by_s, 1000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(reg.model.by_s, 
                     variable.names=c("beta","alpha", "sigma"), 
                    n.chains = 4, n.iter=20000)

summary(samp)



```
# this model assumes all trees across all species + sites have the same relationship with summer PDSI + JUNTmax

```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]
Y <- as.vector(log(full.ghcn$RWI)) 

pdsi <- as.vector( full.ghcn$JJA.pdsi)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_pdsi_tmax <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[2]*pdsi[i] + beta[3]*JunTmax[i]
}

# Assume normal priors for betas (because they could be negative or positive)
for(j in 1:3){
beta[j] ~ dnorm(0,0.001)
}



# Prior for the inverse variances
inv.var   ~ dgamma(0.1, 0.1)
sigma     <- 1/sqrt(inv.var)



}"

reg.model.Drought.Tmax <- jags.model(textConnection(model_string_pdsi_tmax), 
                    data = list(Y=Y, n=n, pdsi = pdsi, JunTmax = JunTmax))

update(reg.model.Drought.Tmax, 10000, progress.bar="none"); # Burnin for 10000 samples

samp <- coda.samples(reg.model.Drought.Tmax, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=20000, progress.bar="none")

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  
samps.df.sum<- data.frame(mean = samp.df$statistics[2,"Mean"], 
           ci.low = samp.df$quantiles[2,"2.5%"], 
           ci.high = samp.df$quantiles[2,"97.5%"])
  

ggplot(samps.df.sum, aes("sens",mean))+geom_bar(stat = "identity")+
  geom_errorbar(aes(ymin=ci.low, ymax = ci.high), size = 0.2, width = 0.2)

```


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


# this model assumes all trees across all species + sites have the same relationship with summer PDSI + JUNTmax + DBH, but has a power function as the process model:



```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]


Y <- as.vector(log(full.ghcn$RWI)) 

pdsi <- as.vector( full.ghcn$JJA.pdsi)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_DBH_power <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[1]*log(DBH[i])
}

# Assume normal priors for betas (because they could be negative or positive)
#for(j in 1:2){
beta[1] ~ dnorm(0, 0.002)
beta[2] ~ dnormal(0, 0.002)
#}



# Prior for the inverse variances
inv.var   ~ dgamma(0.01, 0.01)
sigma     <- 1/sqrt(inv.var)


}"

reg.model.dbh.power <- jags.model(textConnection(model_string_DBH_power), 
                    data = list(Y=Y, n=n, DBH = DBH))

update(reg.model.dbh.power, 1000); # Burnin for 1000 samples

samp <- coda.samples(reg.model.dbh.power, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=2000)

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  
samp.dbh.pwr <- do.call(rbind.data.frame, samp)


# compare to the estimates from OLS:

summary(lm(Y ~ log(DBH)))
```
# this model assumes all trees across all species + sites have the same relationship with summer PDSI + JUNTmax + DBH, but has a power function as the process model:

```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]
Y <- as.vector((full.ghcn$RWI)) 

pdsi <- as.vector( full.ghcn$JJA.pdsi)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_pdsi_tmax_DBH_power <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dlnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[2]*log((pdsi[i]+10)/20) + beta[3]*log(JunTmax[i]) + beta[4]*log(DBH[i])
}

# Assume normal priors for betas (because they could be negative or positive)
for(j in 1:4){
beta[j] ~ dlnorm(0,0.001)
}



# Prior for the inverse variances
inv.var   ~ dgamma(0.1, 0.1)
sigma     <- 1/sqrt(inv.var)


}"

reg.model.Drought.Tmax.dbh.power <- jags.model(textConnection(model_string_pdsi_tmax_DBH_power), 
                    data = list(Y=Y, n=n, pdsi = pdsi, JunTmax = JunTmax, DBH = DBH))

update(reg.model.Drought.Tmax.dbh.powe, 10000, progress.bar="none"); # Burnin for 10000 samples

samp <- coda.samples(reg.model.Drought.Tmax.dbh, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=20000, progress.bar="none")

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  

```
# model assumes a power function relationship between growth ~ beta0x(DBH^beta1)x(DBH^2^beta2)x(droghtindex^beta3)x(JunTmax^beta4)
# will need to scale pdsi such that: drought index == ((pdsi+10)/20)

```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]
Y <- as.vector(log(full.ghcn$RWI)) 

pdsi <- as.vector( (full.ghcn$JJA.pdsi + 10)/20)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_pdsi_tmax_DBH <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[2]*pdsi[i] + beta[3]*JunTmax[i] + beta[4]*DBH[i]
}

# Assume normal priors for betas (because they could be negative or positive)
for(j in 1:4){
beta[j] ~ dnorm(0,0.001)
}



# Prior for the inverse variances
inv.var   ~ dgamma(0.1, 0.1)
sigma     <- 1/sqrt(inv.var)



}"

reg.model.Drought.Tmax.dbh <- jags.model(textConnection(model_string_pdsi_tmax_DBH), 
                    data = list(Y=Y, n=n, pdsi = pdsi, JunTmax = JunTmax, DBH = DBH))

update(reg.model.Drought.Tmax.dbh, 10000, progress.bar="none"); # Burnin for 10000 samples

samp <- coda.samples(reg.model.Drought.Tmax.dbh, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=20000, progress.bar="none")

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  

```

