---
title: "BAI_models"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rjags)
library(ggplot2)

# some initial data checking:
full.ghcn <- read.csv("outputs/data/rwi_age_dbh_ghcn.df")
BAI <- full.ghcn$RWI
hist(BAI)
logBAI<- hist(log(BAI)) # approximates normal when log transformed

```

## Initial bayesian linear regression of climate on Basal Area Index
# this model assumes all trees across all species + sites + forest types have the same relationship with PDSI

```{r}



summary(full.ghcn)
# get all records that have all RWI and don't have negative diams or NA diams
full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH > 0 & !is.na(full.ghcn$DBH),]
Y <- as.vector(log(full.ghcn$RWI)) 
#Y     <- 100*dat[,2]
#Y     <- (Y-mean(Y))/sd(Y)

# standardise predictor variables to have mean 0 and sd = 1
DI.scaled = scale(full.ghcn$JJA.pdsi, center= TRUE, scale=TRUE)
DBH.scaled = scale(full.ghcn$DBH, center= TRUE, scale=TRUE)
T.scaled = scale(full.ghcn$JUNTmax, center= TRUE, scale=TRUE)
full.ghcn$DI.scaled = as.vector(scale(full.ghcn$JJA.pdsi, center = TRUE, scale = TRUE))
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))

#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode

summary(lm(Y ~ log(DBH)))



# population model for the response of each BAI to each year of climate:
population_model <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1 +  beta2*DI.scaled[i] + beta3*DBH.scaled[i] # use Drought index

res[i] <- Y[i] - gfunc[i]   # residual between actual and predicted
emp.new[i] ~ dnorm(gfunc[i], inv.var) 
res.new[i] <- emp.new[i] - gfunc[i]

}

# Assume normal priors for betas (because they could be negative or positive)

beta1 ~ dnorm(0, 0.01)
beta2 ~ dnorm(0, 0.01)
beta3 ~ dnorm(0,0.01)



# Non-informative Prior for the inverse variances
inv.var   ~ dgamma(0.01, 0.01)
sigma     <- 1/sqrt(inv.var)

#Derived parameters
  fit <- sum(res[])
  fit.new <- sum(res.new[])



}"


sum.lin.reg <- lm(full.ghcn$RWI ~ log(full.ghcn$DI.scaled) + log(full.ghcn$DBH.scaled))
lin.rgr.ests<- summary(sum.lin.reg)$coefficients
# specify initial conditions for the three chains
initsList <- list(
  list(
    # chain 1 has low estimates
    beta1 = lin.rgr.ests[1,1] - 5*lin.rgr.ests[1,2],
    beta2 = lin.rgr.ests[2,1] - 5*lin.rgr.ests[2,2], 
    
    inv.var = 0.0001
  ), 
  # chain 2 has high values
  list(
    beta1 = lin.rgr.ests[1,1] + 5*lin.rgr.ests[1,2],
    beta2 = lin.rgr.ests[2,1] + 5*lin.rgr.ests[2,2], 
    #beta3 = lin.rgr.ests[3,1] + 5*lin.rgr.ests[3,2], 
    inv.var = 1
  ), 
  list(
    # chain 3 has a mix
    beta1 = lin.rgr.ests[1,1] + 5*lin.rgr.ests[1,2],
    beta2 = lin.rgr.ests[2,1] - 5*lin.rgr.ests[2,2], 
    #beta3 = lin.rgr.ests[3,1] + 5*lin.rgr.ests[3,2], 
   inv.var = 100
  )
)

# now 
reg.model.age <- jags.model(textConnection(population_model), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled), inits = initsList, n.chains = 3)

update(reg.model.age, 1000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(reg.model.age, 
                     variable.names=c("beta1", "beta2","beta3","sigma"), 
                    n.chains = 3, n.iter=2000)

#lin.reg.bayes <- as.mcmc(samp[[1]])
summary(samp)
plot(samp)
traceplot(samp)
gelman.diag(samp)
gelman.plot(samp)


#Extract the samples for each parameter

 samps       <- samp[[1]]
 #Yp.samps    <- samps[,1:n] 
 alpha.samps <- samps[,1]
 beta.samps  <- samps[,2:3]
 sigma.samps <- samps[,4]

# Compute the posterior mean for the plug-in predictions  

 beta.mn  <- colMeans(beta.samps)
 sigma.mn <- mean(sigma.samps)
 alpha.mn <- mean(alpha.samps) 

 
  DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.25)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.25)
 
 # something like:
 Xp <- expand.grid(DIprobe, DBHprobe)
 #Xp <- as.matrix(Xp)
# Plot the Posterior Predictive Density and plug-in
np <- length(Xp$Var1)
ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   # Plug-in
   mu <- alpha.mn+sum(Xp[j,]*beta.mn)
   ypred[[j]]  <- rnorm(20000, mu, sigma.mn)
   #plot(density(ypred[[j]]),col=2)
  
   # Truth
   #abline(v=mean(ypred),col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- data.frame(do.call(rbind, ypred))

Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg/Ypred_by_drought.png")
ggplot(Xp, aes(Var1,MeanY))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()
png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg/Ypred_by_DBH.png")
ggplot(Xp, aes(Var2,MeanY))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg/Ypred_by_drought_DBH.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)
dev.off()

#set.seed(13)
m <- 10000
chains <- samp[[1]][,1:4]
chains2 <- samp[[2]][,1:4]

postDraws <- chains[sample(nrow(chains),size=m,replace=TRUE),]



# Sample m draws of y.rep (n obs each) from likelihood p(y|theta), using thetas sampled above. Approximates posterior predictive distribution p(y.rep|y)
n <- nrow(full.ghcn)
y.rep <- matrix(NA, nrow=n, ncol=m)
for (i in 1:m){
  y.rep[,i] <- rnorm(n = n, postDraws[i,"fit"], postDraws[i,"fit.new"])
}

# check to see if the predicted yrep alighs with data y max
T1.y <- max(Y)
T1.yrep <- apply(y.rep, 2, max)
hist(T1.yrep)


abline(v=T1.y,col="red",lwd=2)


pppval.max <- sum(T1.yrep>=T1.y)/m
print(pppval.max)

# quick check to see how params compare to OLS 
summary(lm(Y ~ full.ghcn$DI.scaled))

# plot mcmc + the parameter distn
coda:::plot.mcmc(samp)
samp.basic.reg <- samp
# save a data frame with beta2 sensitivity and the 
samp.basic.reg.df <- summary(samp)
  
samp.basic.df.sum<- data.frame(mean = samp.df$statistics[2,"Mean"], 
           ci.low = samp.df$quantiles[2,"2.5%"], 
           ci.high = samp.df$quantiles[2,"97.5%"])
  


```

# Create random effects for sites:
```{r}
population_model_site_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[SITE[i]] + beta2[SITE[i]]*DI.scaled[i] + beta3[SITE[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 

res[i] <- Y[i] - gfunc[i]   
emp.new[i] ~ dnorm(gfunc[i], sigma)
res.new[i] <- emp.new[i] - gfunc[i]
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
}

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.0001, 0.0001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)




# derived parameters
  fit <- sum(res[])
  fit.new <- sum(res.new[])
  Yp <- mean(Y)

}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)



reg.model.by_s <- jags.model(textConnection(population_model_site_re), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, SITE = as.numeric(full.ghcn$site), S = unique(full.ghcn$site)), n.chains = 3, n.adapt = 100)

update(reg.model.by_s, 1000); # Burnin for 1000 samples to start, then go higher later

samp.plot.re <- coda.samples(reg.model.by_s, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3"), 
                    n.chains = 3, n.iter=3000)

summary(samp.plot.re)
plot(samp.plot.re)

gelman.diag(samp.plot.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.plot.re[[1]]
 #Yp.samps    <- samps[,1] 
 alpha.samps <- samps[,1:16] # one alpha for each of 16 sites
 beta1.samps  <- samps[,17:32]
 beta2.samps <- samps[,33:48]
 sigma.samps <- samps[,49]
 sigma_betas <- samps[,50:52]



# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe, site = 1:16)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(20000, mu, sigma.mn)
  # lines(density(y),col=2)

   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)

Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of D
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_site_re/Ypred_by_drought_site.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(site)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_site_re/Ypred_by_DBH.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(site)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_site_re/Ypred_by_drought_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(site))
dev.off()

# since site 10 is variable, remove:

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_site_re/Ypred_by_drought_DBH_site_site_10_omitted.png")
ggplot(Xp[Xp$site != 10,], aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(site))
dev.off()


```


#this is a model with cohort effects and re effects @ the cohort level rather than the site level:

```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
population_model_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*DI.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 

res[i] <- Y[i] - gfunc[i]   
emp.new[i] ~ dnorm(gfunc[i], sigma)
res.new[i] <- emp.new[i] - gfunc[i]
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(c in 1:length(C)){
beta1[c] ~ dnorm(mu_beta1, inv_beta1)
beta2[c] ~ dnorm(mu_beta2, inv_beta2)
beta3[c] ~ dnorm(mu_beta3, inv_beta3)
}

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)



  
# Contrasts:
    betadiff <- beta2[1]-beta2[2] # difference in modes of pitcher and 1st base positions
    #betadiffProb <- step(betadiff) # returns a 1 if c1Minusc3 > 0


# get Ypred for test data:
for(i in 1:np){
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*DI.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 

}


}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)



reg.model.by_age <- jags.model(textConnection(population_model_cohort_re), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, cohort = as.numeric(full.ghcn$ageclass), C = unique(full.ghcn$ageclass), np=length(test$year), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass)), n.chains = 3, n.adapt = 100)


update(reg.model.by_age, 1000); # Burnin for 1000 samples to start, then go higher later

samp.age.re <- coda.samples(reg.model.by_age, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "betadiff", "Yp"), 
                    n.chains = 3, n.iter=2000, thin = 10)

summary(samp.age.re)
plot(samp.age.re)

gelman.diag(samp.age.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.age.re[[1]]
 Yp.samps    <- samps[,1:2756] 
 alpha.samps <- samps[,2757:2758] # one alpha for each of 16 sites
 beta1.samps  <- samps[,2759:2760]
 beta2.samps <- samps[,2761:2762]
 beta.diff.samps <- samps[,2763]
 sigma.samps <- samps[,2764]
 sigma_betas <- samps[,2765:2767]

# plot predicted vs. observed test data:
 png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_re/Ypred_vs_obs.png")
 plot(colMeans(exp(Yp.samps)), test$RWI, xlab = "Mean Posterior Predicted Growth", ylab = "Observed Tree Ring Growth")
 abline(a = 0, b = 1, col = "red")
 dev.off()
 
 
 
 png("outputs/growth_model/basic_reg_cohort_re/marginal_alphas.png")
par(mfrow=c(1,3))
hist(alpha.samps[,1], main = "alpha Forest")
hist(alpha.samps[,2], main = "alpha Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_cohort_re/marginal_beta1s.png")
par(mfrow=c(1,3))
hist(beta1.samps[,1], main = "beta2 Forest")
hist(beta1.samps[,2], main = "beta2 Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()


png("outputs/growth_model/basic_reg_cohort_re/marginal_beta1_diff.png")

hist(beta1.diffs, main = "Difference between savanna and forest beta1")
abline(v=0,col="red")
dev.off()

png("outputs/growth_model/basic_reg_cohort_re/marginal_beta2s.png")
par(mfrow=c(1,3))
hist(beta2.samps[,1], main = "beta3 Forest")
hist(beta2.samps[,2], main = "beta3 Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("Random Intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("Drought Index sensitivity")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("DBH Index sensitivity")

library(cowplot)
png(width = 4, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_cohort_re/param_marginal_distn_by_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

 
# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(20000, mu, sigma.mn)
  # lines(density(y),col=2)

   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)

Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of 
Xp$cohort <- ifelse(Xp$cohort == 1, "Past", "Modern")
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_re/Ypred_by_drought_site_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_re/Ypred_by_DBH_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")+theme_black()
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_re/Ypred_by_drought_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(cohort))+theme_black()
dev.off()


```


#this is a model with structure effects and re effects @ the structure (forest vs. savanna) level rather than the site level:

```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
population_model_structure_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[structure[i]] + beta2[structure[i]]*DI.scaled[i] + beta3[structure[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 

res[i] <- Y[i] - gfunc[i]   
emp.new[i] ~ dnorm(gfunc[i], sigma)
res.new[i] <- emp.new[i] - gfunc[i]
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
}

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)


for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[structure.p[i]] + beta2[structure.p[i]]*DI.scaled.p[i] + beta3[structure.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 

}




}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))

full.ghcn <- merge(full.ghcn, structure, by = "site")

reg.model.by_structure <- jags.model(textConnection(population_model_structure_re), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, structure = as.numeric(full.ghcn$structure), SF = unique(full.ghcn$structure), np=length(test$year), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, structure.p = as.numeric(test$structure)), n.chains = 3, n.adapt = 100)

update(reg.model.by_structure, 1000); # Burnin for 1000 samples to start, then go higher later

samp.structure.re <- coda.samples(reg.model.by_structure, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 15)

summary(samp.structure.re)
plot(samp.structure.re)

gelman.diag(samp.structure.re)
acfplot(samp.structure.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.structure.re[[1]]
 saveRDS(samps, "outputs/growth_model/basic_reg_structure_re/samps.rds")
 Yp.samps    <- samps[,1:length(test$site)] 
 alpha.samps <- samps[,(length(test$site)+1):(length(test$site)+2)] # one alpha for each of 16 sites
 beta1.samps  <- samps[,(length(test$site)+3):(length(test$site)+4)]
 beta2.samps <- samps[,(length(test$site)+5):(length(test$site)+6)]
 sigma.samps <- samps[,(length(test$site)+7)]
 sigma_betas <- samps[,(length(test$site)+8):(length(test$site)+10)]
 
 # derived quantities:
 beta1.diffs <- beta1.samps[,1] - beta2.samps[,2]
hist(beta1.diffs)


 
# plot marginal distributions of each parameter:

png("outputs/growth_model/basic_reg_structure_re/marginal_alphas.png")
par(mfrow=c(1,3))
hist(alpha.samps[,1], main = "alpha Forest")
hist(alpha.samps[,2], main = "alpha Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_structure_re/marginal_beta1s.png")
par(mfrow=c(1,3))
hist(beta1.samps[,1], main = "beta2 Forest")
hist(beta1.samps[,2], main = "beta2 Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()


png("outputs/growth_model/basic_reg_structure_re/marginal_beta1_diff.png")

hist(beta1.diffs, main = "Difference between savanna and forest beta1")
abline(v=0,col="red")
dev.off()

png("outputs/growth_model/basic_reg_structure_re/marginal_beta2s.png")
par(mfrow=c(1,3))
hist(beta2.samps[,1], main = "beta3 Forest")
hist(beta2.samps[,2], main = "beta3 Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c("Forest", "Savanna")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+theme_black()+xlab("random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c("Forest", "Savanna")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+theme_black()+xlab("Drought slopes")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Forest", "Savanna")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+theme_black()+xlab("DBH random slopes")

library(cowplot)
png(width = 4, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_structure_re/param_marginal_distn_by_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()


# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 

 # plot predicted vs. observed:
 png(width = 4, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_structure_re/pred_vs_obs.png")
 plot(colMeans(exp(Yp.samps)), test$RWI, xlab = "Predicted Growth", ylab = "Observed Growth")
abline(a = 0, b = 1, col = "red")
dev.off()
# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  structure= 1:2)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(20000, mu, sigma.mn)
  # lines(density(y),col=2)

   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)

Xp$MeanY <- exp(rowMeans(ypred.df)) # get the means of the posterior to plot the overall effects of 
Xp$structure <- ifelse(Xp$structure == 1, "Forest", "Savanna")
#DBH + DI on predicted growth
png("outputs/growth_model/basic_reg_structure_re/predicted_y.png")
#par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

#plot(density(d13pred.df), main = "d13pred, line = d13data")
#abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()
# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_structure_re/Ypred_by_drought_structure.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(structure)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_structure_re/Ypred_by_DBH_structure.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(structure)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_structure_re/Ypred_by_drought_DBH_structure.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(structure))
dev.off()


```
# could make a model with site or stand structure by ageclass as the factor to take random effects on:
```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
population_model_structure_x_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[struct.cohort[i]] + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 

#res[i] <- Y[i] - gfunc[i]   
#emp.new[i] ~ dnorm(gfunc[i], sigma)
#res.new[i] <- emp.new[i] - gfunc[i]
}

# Prediction
  for(i in 1:np){
    Yp[i]  ~ dnorm(mup[i],inv.var)
    mup[i] <- beta1[struct.cohort.p[i]] + beta2[struct.cohort.p[i]]*DI.scaled.p[i] + beta3[struct.cohort.p[i]]*DBH.scaled.p[i] 
  }

# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
}



# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)

inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)






}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
plot <- unique(full.ghcn$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))



library(caTools)
msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]



# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)


reg.model.by_structure_x_cohort <- jags.model(textConnection(population_model_structure_x_cohort_re), 
                    data = list(Y=log(train$RWI), n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(train$struct.cohort.code), np = length(test$DBH.scaled),
   struct.cohort.p = as.numeric(test$struct.cohort.code), DBH.scaled.p = test$DBH.scaled, DI.scaled.p = test$DI.scaled), n.chains = 3, n.adapt = 100)

update(reg.model.by_structure_x_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


samp.structure.cohort.re <- coda.samples(reg.model.by_structure_x_cohort, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2","sigma_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 15)

summary(samp.structure.cohort.re)
plot(samp.structure.cohort.re)

gelman.diag(samp.structure.cohort.re)
acfplot(samp.structure.cohort.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp.structure.cohort.re[[1]]
 saveRDS(samps, "outputs//growth_model/basic_reg_struct_x_cohort_re/samps.rds")
 #Yp.samps    <- samps[,1] 
 Yp.samps <- samps[,1:3726] 
 alpha.samps  <- samps[,3727:3730]# one alpha for each of 4 cohort-strcuture groups
 beta2.samps <- samps[,3731:3734]
 beta3.samps <- samps[,3735:3738]
 sigma.samps <- samps[,3739]
 sigma_betas <- samps[,3740:3742]

 
# plot predicted vs. observed:
test$mean.Y <- colMeans(exp(Yp.samps))
 
ggplot(test, aes(RWI, mean.Y))+geom_point()+geom_abline(intercept = 0, slope = 1,  color = "red")+xlim(0,5)+ylim(0,5)

# get difference between beta2.samps:
oneminustwo <- beta2.samps[,1] - beta2.samps[,2]
oneminusthree <- beta2.samps[,1] - beta2.samps[,3]
oneminusfour <- beta2.samps[,1] - beta2.samps[,4]
twominusthree <- beta2.samps[,2] - beta2.samps[,3]
twominusfour <- beta2.samps[,2] - beta2.samps[,4]
threeminusfour <- beta2.samps[,3] - beta2.samps[,4]
# calculate MSPE
# get posterior predictive density

# plot marginal distributions of each parameter:
png("outputs/growth_model/basic_reg_struct_x_cohort_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Forest")
hist(alpha.samps[,2], main = "alpha Modern-Forest")
hist(alpha.samps[,3],  main = "alpha Past-Savanna ")
hist(alpha.samps[,4],  main = "alpha Modern-Savanna")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_struct_x_cohort_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Forest")
hist(beta2.samps[,2], main = "beta2 Modern-Forest")
hist(beta2.samps[,3],  main = "beta2 Past-Savanna")
hist(beta2.samps[,4],  main = "beta2 Modern-Savanna")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/basic_reg_struct_x_cohort_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Forest")
hist(beta3.samps[,2], main = "beta3 Modern-Forest")
hist(beta3.samps[,3],  main = "beta3 Past-Savanna")
hist(beta3.samps[,4],  main = "beta3 Modern-Savanna")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(train$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c(unique(train$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Drought Index slope")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(train$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("DBH slope")

library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_struct_x_cohort_re/param_marginal_distn_bycohort_struct.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()


Yp <- data.frame(Yp.samps)
colnames(Yp) <- c(paste0("YP-",c(unique(full.ghcn$struct.cohort))))
Yp$num <- rownames(Yp)
Yp.m <- melt(Yp, id.vars=c("num"))
Yp.m$DBHindex <- Xp$Var2
Yp.m$DIindex <- Xp$Var1
Yp.m$struct.cohort <- Xp$struct.cohort
ggplot(Yp.m, aes(value, color = as.factor(Yp.m$struct.cohort)))+geom_density(alpha = 0.5)+theme_bw()
library(ggridges)

ggplot(Yp.m, aes(x = value, y = as.factor(DIindex))) + 
  geom_density_ridges()

ggplot(full.ghcn, aes(x = log(RWI), y = as.factor(struct.cohort))) + 
  geom_density_ridges()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta2.samps)
 beta2.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 


# Plot the Posterior Predictive Density and plug-in
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 ypred.yp <- list()
 diff <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)
  # lines(density(y),col=2)
   #ypred.yp[[j]] <- Yp.samps[,j]
   #diff[[j]] <- ypred[[j]] - Yp.samps[[j]]
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
#diff.df <- do.call(rbind, diff)
#ypred.yp.df <- do.call(rbind, ypred.yp)

Xp$MeanY <- exp(rowMeans(ypred.df))
#Xp$MeanYhat <- exp(rowMeans(ypred.yp.df))# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
dev.off()


```


# model for cohort effects and site level effects, heirarchically:
```{r}

cohort_model_site_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*DI.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)
}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)


for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*DI.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 
}

}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode


msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]


cohort.model.re <- jags.model(textConnection(cohort_model_site_re), 
                    data = list(Y=log(train$RWI), n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, cohort = as.numeric(train$ageclass), S = unique(train$ageclass),
                    plot = as.numeric(train$site), ind = unique(train$site), np = length(test$DBH.scaled), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass), SP = unique(test$ageclass),
                    plot.p = as.numeric(test$site), ind.p = unique(test$site)), n.chains = 3, n.adapt = 100)

update(cohort.model.re, 2000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(cohort.model.re, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2", "sigma_beta3", "mu_beta1", "mu_beta2", "mu_beta3", "Yp"), 
                    n.chains = 3, n.iter=20000, thin = 10)

summary(samp)
traceplot(samp)
gelman.diag(samp)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp[[1]]
 saveRDS(samps, "outputs/growth_model/basic_reg_cohort_site_re/samps.rds")
 Yp.samps    <- samps[,1:2780] 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,2781:2782]
 beta2.samps <- samps[,2783:2784]
 beta3.samps <- samps[,2785:2786]
 mu_beta1.samps <- samps[,2787:2800]
 mu_beta2.samps <- samps[,2801:2814]
 mu_beta3.samps <- samps[,2815:2828]
 sigma.samps <- samps[,2829]
 sigma_betas <- samps[,2830:2832]

png("outputs/growth_model/basic_reg_cohort_site_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past")
hist(alpha.samps[,2], main = "alpha Modern")
#hist(alpha.samps[,3],  main = "alpha Past-Forest")
#hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_cohort_site_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta2.samps[,2], main = "beta2 Modern-Savanna")
#hist(beta2.samps[,3],  main = "beta2 Past-Forest")
#hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()





png("outputs/growth_model/basic_reg_cohort_site_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
#hist(beta3.samps[,3],  main = "beta3 Past-Forest")
#hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_re/marginal_mu_beta2s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta2.samps[,i], main = paste(colnames(mu_beta2.samps)[i]))
}
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_re/marginal_mu_beta3s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta3.samps[,i], main = paste(colnames(mu_beta3.samps)[i]))
}
dev.off()

png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_re/marginal_mu_beta1s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta1.samps))){
  hist(mu_beta1.samps[,i], main = paste(colnames(mu_beta1.samps)[i]))
}
dev.off()

# plot predicted vs. observed:
png("outputs/growth_model/basic_reg_cohort_site_re/pred_vs_obs.png")
plot(colMeans(exp(Yp.samps)), test$RWI) 
abline(a = 0, b = 1, col = "red")
dev.off()



# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-", c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Random intercepts")+theme_black()


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Drought Index slope")+theme_black()


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("DBH slope")+theme_black()

library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_cohort_site_re/param_marginal_distn_bycohort.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 beta3.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
 #mu_beta1.samps <- colMeans(mu_beta1.samps) 
 #mu_beta2.samps <- colMeans(mu_beta2.samps) 
 #mu_beta3.samps <- colMeans(mu_beta3.samps) 


# get posterior predictions:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2, site = as.numeric(unique(full.ghcn$site)))
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:



 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 
 
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

        
        alpha1.mn <- rnorm(1000, mu_beta1.samps[Xp[j,4]], mean(sigma_betas[,1]) ) # check the sigma betas
        beta2.mn <- rnorm(1000, mu_beta2.samps[Xp[j,4]], mean(sigma_betas[,2]) ) # check the sigma betas
        beta3.mn <- rnorm(1000, mu_beta3.samps[Xp[j,3]], mean(sigma_betas[,3]) ) # check the sigma betas
       
   mu <- alpha1.mn + beta2.mn*Xp[j,1] + beta2.mn*Xp[j,2]   # use
   
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   
   ypred[[j]]  <- mu
  # lines(density(y),col=2)
   
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)


Xp$MeanY <- exp(rowMeans(ypred.df))

Xp$cohort <- ifelse(Xp$cohort == 2, "Past",  
                       ifelse(Xp$cohort == 1, "Modern",NA))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1, MeanY, color = as.factor(site), shape = as.factor(cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(cohort))
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site))
dev.off()


png(height = 10, width = 10, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site) + as.factor(cohort))
dev.off()

```


# model for cohort effects with summer VPD instead of PDSI
```{r}

cohort_model_site_VPD_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*VPD.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)
}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)


for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*VPD.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 
}

}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode
full.ghcn$jja.VPDmax.scaled <- as.vector(scale(full.ghcn$jja.VPDmax, center = TRUE, scale = TRUE))


msk <- sample.split( full.ghcn, SplitRatio = 3/4, group = NULL )

train <- full.ghcn[msk,]
test <- full.ghcn[!msk,]


cohort.model.VPD.re <- jags.model(textConnection(cohort_model_site_VPD_re ), 
                    data = list(Y=log(full.ghcn$RWI), n=length(full.ghcn$RWI), VPD.scaled = full.ghcn$jja.VPDmax.scaled, DBH.scaled = full.ghcn$DBH.scaled, cohort = as.numeric(full.ghcn$ageclass), S = unique(full.ghcn$ageclass),
                    plot = as.numeric(full.ghcn$site), ind = unique(full.ghcn$site), np = length(test$DBH.scaled),  VPD.scaled.p = test$jja.VPDmax.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass), SP = unique(test$ageclass),
                    plot.p = as.numeric(test$site), ind.p = unique(test$site)), n.chains = 3, n.adapt = 100)

update(cohort.model.VPD.re , 2000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(cohort.model.VPD.re , 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2", "sigma_beta3", "mu_beta1", "mu_beta2", "mu_beta3", "Yp"), 
                    n.chains = 3, n.iter=2000, thin = 10)

summary(samp)
traceplot(samp)
gelman.diag(samp)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp[[1]]
 saveRDS(samps, "outputs/growth_model/basic_reg_cohort_site_VPD_re/samps.rds")
 Yp.samps    <- samps[,1:2756] 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,2757:2758]
 beta2.samps <- samps[,2759:2760]
 beta3.samps <- samps[,2761:2762]
 mu_beta1.samps <- samps[,2763:2776]
 mu_beta2.samps <- samps[,2777:2790]
 mu_beta3.samps <- samps[,2791:2804]
 sigma.samps <- samps[,2805]
 sigma_betas <- samps[,2806:2808]

png("outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past")
hist(alpha.samps[,2], main = "alpha Modern")
#hist(alpha.samps[,3],  main = "alpha Past-Forest")
#hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta2.samps[,2], main = "beta2 Modern-Savanna")
#hist(beta2.samps[,3],  main = "beta2 Past-Forest")
#hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()





png("outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
#hist(beta3.samps[,3],  main = "beta3 Past-Forest")
#hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_mu_beta2s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta2.samps[,i], main = paste(colnames(mu_beta2.samps)[i]))
}
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_mu_beta3s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta3.samps[,i], main = paste(colnames(mu_beta3.samps)[i]))
}
dev.off()

png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_cohort_site_VPD_re/marginal_mu_beta1s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta1.samps))){
  hist(mu_beta1.samps[,i], main = paste(colnames(mu_beta1.samps)[i]))
}
dev.off()

# plot predicted vs. observed:
png("outputs/growth_model/basic_reg_cohort_site_VPD_re/pred_vs_obs.png")
plot(colMeans(exp(Yp.samps)), test$RWI) 
abline(a = 0, b = 1, col = "red")
dev.off()



# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-", c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("Random intercepts")+theme_black()


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("VPD Index slope")+theme_black()


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("DBH slope")+theme_black()

library(cowplot)
png(width = 5, height = 6, units = "in", res = 300, "outputs/growth_model/basic_reg_cohort_site_VPD_re/param_marginal_distn_bycohort.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(alpha.samps)
 beta2.mn  <- colMeans(beta2.samps)
 beta3.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
 #mu_beta1.samps <- colMeans(mu_beta1.samps) 
 #mu_beta2.samps <- colMeans(mu_beta2.samps) 
 #mu_beta3.samps <- colMeans(mu_beta3.samps) 


# get posterior predictions:
 DIprobe <- seq(range(full.ghcn$jja.VPDmax.scaled)[1], range(full.ghcn$jja.VPDmax.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2, site = as.numeric(unique(full.ghcn$site)))
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:



 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 
 
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

        
        alpha1.mn <- rnorm(1000, mu_beta1.samps[Xp[j,4]], mean(sigma_betas[,1]) ) # check the sigma betas
        beta2.mn <- rnorm(1000, mu_beta2.samps[Xp[j,4]], mean(sigma_betas[,2]) ) # check the sigma betas
        beta3.mn <- rnorm(1000, mu_beta3.samps[Xp[j,3]], mean(sigma_betas[,3]) ) # check the sigma betas
       
   mu <- alpha1.mn + beta2.mn*Xp[j,1] + beta2.mn*Xp[j,2]   # use
   
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   
   ypred[[j]]  <- mu
  # lines(density(y),col=2)
   
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)


Xp$MeanY <- rowMeans(exp(ypred.df))

Xp$cohort <- ifelse(Xp$cohort == 2, "Past",  
                       ifelse(Xp$cohort == 1, "Modern",NA))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_VPD_struct_x_cohort.png")
ggplot(Xp, aes(Var1, MeanY, color = as.factor(site), shape = as.factor(cohort)))+geom_point()+xlab("VPD Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_VPD_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(cohort))
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_VPD_re/Ypred_by_VPD_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site))
dev.off()


png(height = 10, width = 10, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site_cohort.png")
ggplot(Xp[!Xp$site %in% "10",], aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site) + as.factor(cohort))
dev.off()

```

# cohort model for only comparable drought years:
# model for cohort effects and site level effects, heirarchically:
```{r}
cohort_model_dry_site_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1[cohort[i]] + beta2[cohort[i]]*DI.scaled[i] + beta3[cohort[i]]*DBH.scaled[i]   # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
beta1[s] ~ dnorm(mu_beta1[plot[s]], inv_beta1)
beta2[s] ~ dnorm(mu_beta2[plot[s]], inv_beta2)
beta3[s] ~ dnorm(mu_beta3[plot[s]], inv_beta3)
}


for(j in 1:length(ind)){
# use normal hyperpriors for each hyperparamters 
mu_beta1[j] ~ dnorm(0, 0.5)
mu_beta2[j] ~ dnorm(0, 0.5)
mu_beta3[j] ~ dnorm(0, 0.5)

}

inv_beta1   ~ dgamma(0.001, 0.001)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.001, 0.001)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.001, 0.001)
sigma_beta3 <- 1/sqrt(inv_beta3)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.0001, 0.0001)
sigma     <- 1/sqrt(inv.var)

# predictions for the model:
for(i in 1:np){
# process model
Yp[i]   ~ dnorm(gfuncp[i], inv.var) # where Yi is already log transformed

# function g()
gfuncp[i] <- beta1[cohort.p[i]] + beta2[cohort.p[i]]*DI.scaled.p[i] + beta3[cohort.p[i]]*DBH.scaled.p[i]   # use Drought index as a scaled variable 
}


}"




#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode

dry <- quantile(full.ghcn$JJA.pdsi, 0.25) # value of the driest years
wet <- quantile(full.ghcn$JJA.pdsi, 0.75) # value of the wettest years

pre.dry <- full.ghcn[full.ghcn$year < 1950 & full.ghcn$Jul.pdsi <= dry & full.ghcn$ageclass %in% "Past",]
pre.dry$class <- "pre-1950"
pre.dry$climclass <- "Dry_0.25"
post.dry <- full.ghcn[full.ghcn$year >=1950 & full.ghcn$Jul.pdsi <= dry & full.ghcn$ageclass %in% "Modern" ,]
post.dry$class <- "post-1950"
post.dry$climclass <- "Dry_0.25"

pre.wet <- full.ghcn[full.ghcn$year < 1950 & full.ghcn$Jul.pdsi >= wet & full.ghcn$ageclass %in% "Past",]
pre.wet$class <- "pre-1950"
pre.wet$climclass <- "Wet_0.25"
post.wet <- full.ghcn[full.ghcn$year >=1950 & full.ghcn$Jul.pdsi >= wet & full.ghcn$ageclass %in% "Modern" ,]
post.wet$class <- "post-1950"
post.wet$climclass <- "Wet_0.25"

# combine the wet and dry data sets:
dry.yrs <- rbind(post.dry, pre.dry)
msk <- sample.split( dry.yrs, SplitRatio = 3/4, group = NULL )

train <- dry.yrs[msk,]
test <- dry.yrs[!msk,]

cohort.model.dry.re <- jags.model(textConnection(cohort_model_dry_site_re), 
                    data = list(Y=log(train$RWI), n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, cohort = as.numeric(train$ageclass), S = unique(train$ageclass),
                    plot = as.numeric(train$site), ind = unique(train$site),  np=length(test$RWI), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, cohort.p = as.numeric(test$ageclass), SP = unique(test$ageclass),
                    plot.p = as.numeric(test$site), ind.p = unique(test$site)), n.chains = 3, n.adapt = 100)

update(cohort.model.dry.re, 2000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(cohort.model.dry.re, 
                     variable.names=c("beta1", "beta2","beta3","sigma", "sigma_beta1", "sigma_beta2", "sigma_beta3", "mu_beta1", "mu_beta2", "mu_beta3","Yp"), 
                    n.chains = 3, n.iter=10000, thin = 10)

summary(samp)
traceplot(samp)
gelman.diag(samp)



#Extract the samples for each parameter for a basic exploration of effects

 samps       <- samp[[1]]
 
 saveRDS(samps, "outputs/growth_model/basic_reg_dry_cohort_site_re/samps.rds")
 Yp.samps    <- samps[,1:414] 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,415:416]
 beta2.samps <- samps[,417:418]
 beta3.samps <- samps[,419:420]
 mu_beta1.samps <- samps[,421:434]
 mu_beta2.samps <- samps[,435:448]
 mu_beta3.samps <- samps[,449:462]
 sigma.samps <- samps[,463]
 sigma_betas <- samps[,464:466]

 
png("outputs/growth_model/basic_reg_dry_cohort_site_re/pred_vs_obs.png")
plot(colMeans(exp(Yp.samps)), test$RWI) 
abline(a = 0, b = 1, col = "red")
dev.off()

residual <- colMeans(exp(Yp.samps)) - test$RWI

hist(residual)


png("outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_alphas.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past")
hist(alpha.samps[,2], main = "alpha Modern")
#hist(alpha.samps[,3],  main = "alpha Past-Forest")
#hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_beta1s.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta2.samps[,2], main = "beta2 Modern-Savanna")
#hist(beta2.samps[,3],  main = "beta2 Past-Forest")
#hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()





png("outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_beta2s.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
#hist(beta3.samps[,3],  main = "beta3 Past-Forest")
#hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_mu_beta2s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta2.samps))){
  hist(mu_beta2.samps[,i], main = paste(colnames(mu_beta2.samps)[i]))
}
dev.off()


png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_mu_beta3s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta3.samps))){
  hist(mu_beta3.samps[,i], main = paste(colnames(mu_beta3.samps)[i]))
}
dev.off()

png(height = 10, width = 10, units = "in", res = 300,"outputs/growth_model/basic_reg_dry_cohort_site_re/marginal_mu_beta1s.png")
par(mfrow=c(4,4))
for(i in 1:length(colnames(mu_beta1.samps))){
  hist(mu_beta1.samps[,i], main = paste(colnames(mu_beta1.samps)[i]))
}
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-", c("Modern", "Past")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("Random intercepts")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c("Modern", "Past")))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("Drought Sensitivity")+geom_segment( aes(x=quantile(b2[,1], 0.05), xend=quantile(b2[,1], 0.05), y= 0, yend = 2.5), col = "white", linetype = "dashed")+geom_segment( aes(x=quantile(b2[,1], 0.95), xend=quantile(b2[,1], 0.95), y= 0, yend = 2.5), col = "white", linetype = "dashed")+geom_segment( aes(x=quantile(b2[,2], 0.05), xend=quantile(b2[,2], 0.05), y= 0, yend = 5), col = "blue", linetype = "dashed")+geom_segment( aes(x=quantile(b2[,2], 0.95), xend=quantile(b2[,2], 0.95), y= 0, yend = 5), col = "blue", linetype = "dashed")+ylab("frequency")#+geom_segment( aes(x=quantile(b2[,2], 0.5), xend=quantile(b2[,2], 0.5), y= 0, yend = 29), col = "blue")

# difference between betas:
beta2.diff <- beta2.samps[,1] - beta2.samps[,2]

b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c("Modern", "Past")))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+xlab("DBH slope")



library(cowplot)
png(width = 5, height = 10, units = "in", res = 300, "outputs/growth_model/basic_reg_dry_cohort_site_re/param_marginal_distn_bycohort.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, ncol = 1)
dev.off()

# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 beta3.mn  <- colMeans(beta3.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
 #mu_beta1.samps <- colMeans(mu_beta1.samps) 
 #mu_beta2.samps <- colMeans(mu_beta2.samps) 
 #mu_beta3.samps <- colMeans(mu_beta3.samps) 


# get posterior predictions:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  cohort= 1:2, site = as.numeric(unique(full.ghcn$site)))
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:



 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()
 
 
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

        
        alpha1.mn <- rnorm(1000, mu_beta1.samps[Xp[j,4]], mean(sigma_betas[,1]) ) # check the sigma betas
        beta2.mn <- rnorm(1000, mu_beta2.samps[Xp[j,4]], mean(sigma_betas[,2]) ) # check the sigma betas
        beta3.mn <- rnorm(1000, mu_beta3.samps[Xp[j,3]], mean(sigma_betas[,3]) ) # check the sigma betas
       
   mu <- alpha1.mn + beta2.mn*Xp[j,1] + beta2.mn*Xp[j,2]   # use
   
   #mu <- alpha1.mn+sum(Xp[j,1]*beta1.mn, Xp[j,2]*beta2.mn)
   
   ypred[[j]]  <- mu
  # lines(density(y),col=2)
   
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)


Xp$MeanY <- exp(rowMeans(ypred.df))

Xp$cohort <- ifelse(Xp$cohort == 2, "Past",  
                       ifelse(Xp$cohort == 1, "Modern",NA))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1, MeanY, color = as.factor(site), shape = as.factor(cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(cohort))
dev.off()

png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site))
dev.off()


png(height = 10, width = 10, units = "in", res = 200,"outputs/growth_model/basic_reg_cohort_site_re/Ypred_by_drought_DBH_site_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~ as.factor(site) + as.factor(cohort))
dev.off()

```
# intercept only model (mean for iWUE):
```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
iWUE_intercept_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model for iWUE:
iWUE[i]   ~ dnorm(iwuefunc[i], inv.var) # where Yi is already log transformed

# function g()
iwuefunc[i] <- beta1[struct.cohort[i]]

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
}



# use normal hyperpriors for each hyperparamters 

mu_beta1 ~ dnorm(0, 0.1)


inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)



# Non-informative Prior for the inverse population variances

inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)


}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
Y.iwue <- d13$iWUE
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)
# read in VPD data and merge with full data:
full.prism <- read.csv("outputs/data/full_det_prism_rwi.csv")
full.ghcn <- merge(full.ghcn, full.prism[,c("year", "site", "ID", "VPDmax", "jja.VPDmax", "BAL", "jul.BAL", "jul.VPDmax")], by = c("year", "site", "ID"))
full.ghcn$jul.VPDmax.scaled <- as.numeric(scale(full.ghcn$jul.VPDmax))
full.ghcn$iWUE.scaled <- as.numeric(scale(full.ghcn$iWUE))
d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
n = length(full.ghcn$Cor.d13C.suess)


# split into testing and training:
library(caTools)
full.iso <- full.ghcn[!is.na(full.ghcn$iWUE) & !full.ghcn$site %in% "BON",]
#full.iso <- full.ghcn
iWUE.med<- full.iso %>% group_by(struct.cohort, struct.cohort.code) %>% summarise(iWUEmean = median(iWUE, na.rm =TRUE))
msk <- sample.split( full.iso, SplitRatio = 3/4, group = NULL )

train <- full.iso[msk,]
test <- full.iso[!msk,]

iwue_mean <- jags.model(textConnection(iWUE_intercept_re), 
                    data = list(iWUE = train$iWUE, n=length(train$iWUE), struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(train$struct.cohort.code)), n.chains = 3, n.adapt = 100)

update(iwue_mean, 1000); # Burnin for 1000 samples to start, then go higher later


iwue.mean.re <- coda.samples(iwue_mean, 
                     variable.names=c("beta1", "mu_beta1"), 
                    n.chains = 3, n.iter = 20000, thin = 15)

summary(iwue.mean.re )
plot(iwue.mean.re )

gelman.diag(iwue.mean.re )
acfplot(iwue.mean.re )

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- iwue.mean.re [[1]]
 saveRDS(samps, "outputs/growth_model/iWUE_intercept_mod/samps.d13_nobon.rds")
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 #d13pred <- samps
 alpha.samps  <- samps[,1:4]



png("outputs/growth_model/iWUE_intercept_mod/marginal_alphas_v3_iWUE.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")

dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha- ", c("Past-Forest", "Modern-Forest", "Past-Savanna", "Modern-Savanna")))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_black()+ylab("frequency")+xlab("iWUE")


ggplot(a.m, aes(variable, value, fill = variable))+geom_boxplot(alpha = 0.5)+theme_black()+ylab("frequency")+xlab("iWUE")


library(cowplot)
png(width = 7, height = 3, units = "in", res = 300, "outputs/growth_model/iWUE_intercept_mod/param_marginal_distn_bycohort_struct_v3_iwue_random_slopes.png")
plot_grid(alpha.mplots, ncol = 1)
dev.off()


#predict the 
# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues




```

# adding a prediction for stable isotopes (d13C) from tree growth predictions
```{r}
# this model is specified in basically the same as the site level model, but we replace site with "cohort"
d13_model_structure_x_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){
# process model for growth:
Y[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- beta1 + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i]+ beta4[struct.cohort[i]]*jul.VPDmax[i] + beta5[struct.cohort[i]]*iWUE[i] # use Drought index as a scaled variable 

# if there is d13 data, then use Y[i] to predict
#if(d13index[i]){
 # process model for d13C:
 #Y[i]   ~ dnorm(d13func[i], inv.var13) # where Yi is already log transformed
 #d13func[i] <- beta1 + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i] #+ beta4[struct.cohort[i]]*RWI[i] + beta5[struct.cohort[i]]*jul.VPDmax[i]
#}


#res[i] <- Y[i] - gfunc[i]   
#emp.new[i] ~ dnorm(gfunc[i], sigma)
#res.new[i] <- emp.new[i] - gfunc[i]
}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
#beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
# if we assume WUE is known for each group:
#mu_beta2[s] <- gamma1 * exp(-v*iWUE[s])
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
beta4[s] ~ dnorm(mu_beta4, inv_beta4)
beta5[s] ~ dnorm(mu_beta5, inv_beta5)
}


#gamma1 ~ dgamma(0.001, 0.001)
#v ~ dgamma(0.001, 0.001)

# model for stable isotopes:
#for(d in 1:n.d13){

  # process model for growth:
 # Y.d13[d]   ~ dnorm(gfuncd13[d], inv.var) # Model Yi using estimated parameter distributions 

  # function g()
  #gfuncd13[d] <- beta1[struct.cohort.d13[d]] + beta2[struct.cohort.d13[d]]*DI.scaled.d13[d] +         #  beta3[struct.cohort.d13[d]]*DBH.scaled.d13[d]   # use Drought index as a scaled variable 

 # process model for d13C:
 #d13[d]   ~ dnorm(d13func[d], inv.var13) # where Yi is already log transformed
 #d13func[d] <- beta.d131 + beta.d132*Y[d]

#}



# use normal hyperpriors for each hyperparamters 
beta1 ~ dnorm(0, 0.01)
#mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)
mu_beta4 ~ dunif(-2, 2)
mu_beta5 ~ dunif(-2, 2)
#beta.d131 ~ dnorm(0, 2)
#beta.d132 ~ dnorm(0,2)

#inv_beta1   ~ dgamma(0.01, 0.01)
#sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)
inv_beta4   ~ dgamma(0.01, 0.01)
sigma_beta4 <- 1/sqrt(inv_beta4)
inv_beta5   ~ dgamma(0.01, 0.01)
sigma_beta5 <- 1/sqrt(inv_beta5)

#inv.var13 ~ dgamma(0.01, 0.01)
#sigma_13 <- 1/sqrt(inv.var13)


# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)






}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
Y.iwue <- d13$iWUE
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)
# read in VPD data and merge with full data:
full.prism <- read.csv("outputs/data/full_det_prism_rwi.csv")
full.ghcn <- merge(full.ghcn, full.prism[,c("year", "site", "ID", "VPDmax", "jja.VPDmax", "BAL", "jul.BAL", "jul.VPDmax")], by = c("year", "site", "ID"))
full.ghcn$jul.VPDmax.scaled <- as.numeric(scale(full.ghcn$jul.VPDmax))
full.ghcn$iWUE.scaled <- as.numeric(scale(full.ghcn$iWUE))
d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
n = length(full.ghcn$Cor.d13C.suess)


# split into testing and training:
library(caTools)
full.iso <- full.ghcn[!is.na(full.ghcn$iWUE),]
#full.iso <- full.ghcn
iWUE.med<- full.iso %>% group_by(struct.cohort, struct.cohort.code) %>% summarise(iWUEmean = median(iWUE, na.rm =TRUE))
msk <- sample.split( full.iso, SplitRatio = 3/4, group = NULL )

train <- full.iso[msk,]
test <- full.iso[!msk,]

d13.model.by_structure_x_cohort <- jags.model(textConnection(d13_model_structure_x_cohort_re), 
                    data = list(Y = train$RWI, n=length(train$RWI), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, jul.VPDmax = train$jul.VPDmax.scaled, iWUE = train$iWUE.scaled, struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(train$struct.cohort.code)), n.chains = 3, n.adapt = 100)

update(d13.model.by_structure_x_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


d13.structure.cohort.re <- coda.samples(d13.model.by_structure_x_cohort, 
                     variable.names=c("beta1", "beta2","beta3", "beta4", "beta5","sigma_beta2","sigma_beta3", "sigma_beta4","sigma_beta5"), 
                    n.chains = 3, n.iter = 200000, thin = 15)

summary(d13.structure.cohort.re)
plot(d13.structure.cohort.re)

gelman.diag(d13.structure.cohort.re)
acfplot(d13.structure.cohort.re)

#Extract the samples for each parameter for a basic exploration of effects

 samps       <- d13.structure.cohort.re[[1]]
 saveRDS(samps, "outputs/growth_model/d13_reg_struct_x_cohort/samps.wue.rds")
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 #d13pred <- samps
 alpha.samps  <- samps[,1]
 beta2.samps <- samps[,2:5]
 beta3.samps <- samps[,6:9]
 beta4.samps <- samps[,10:13]
 beta5.samps <- samps[,14:17]
 sigma.samps <- samps[,16]
 #sigma13.samps <- samps[,15]
 sigma_betas <- samps[,17:21]
 d13pred <- samps[,18:8228]
 #betad131.samps <- samps[,1]
 #betad132.samps <- samps[,2]

# plot marginal distributions of each parameter:
png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_d13_sigmas_v3_iWUE.png")
par(mfrow=c(2,2))
#hist(betad131.samps, main = "alpha d13")
#hist(betad132.samps, main = "beta d13")
hist(sigma.samps, main = "sigma")
dev.off()

png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_alphas_v3_iWUE.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_beta1s_v3_IWUE.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta2 Past-Savanna")
hist(beta3.samps[,2], main = "beta2 Modern-Savanna")
hist(beta4.samps[,3],  main = "beta2 Past-Forest")
hist(beta2.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/d13_reg_struct_x_cohort/marginal_beta2s_v3_iwue.png")
par(mfrow=c(3,2))
hist(beta3.samps[,1], main = "beta3 Past-Savanna")
hist(beta3.samps[,2], main = "beta3 Modern-Savanna")
hist(beta3.samps[,3],  main = "beta3 Past-Forest")
hist(beta3.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(full.ghcn$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c(unique(full.ghcn$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(full.ghcn$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()

b4 <- data.frame(beta4.samps)
colnames(b4) <- c(paste0("beta3-",c(unique(full.ghcn$struct.cohort))))
b4$num <- rownames(b4)
b4.m <- melt(b4, id.vars=c("num"))
b4.mplots <- ggplot(b4.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()

b5 <- data.frame(beta5.samps)
colnames(b5) <- c(paste0("beta5-",c(unique(full.ghcn$struct.cohort))))
b5$num <- rownames(b5)
b5.m <- melt(b5, id.vars=c("num"))
b5.mplots <- ggplot(b5.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()



library(cowplot)
png(width = 4, height = 8, units = "in", res = 300, "outputs/growth_model/d13_reg_struct_x_cohort/param_marginal_distn_bycohort_struct_v3_iwue_random_slopes.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots, b4.mplots, b5.mplots, ncol = 1)
dev.off()


#predict the 
# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues

pval113.d <- mean(d13pred.df > d13$Cor.d13C.suess) 


Xp$MeanY <- exp(rowMeans(ypred.df))
Xp$Meand13<- rowMeans(d13pred.df)# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()






#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2, Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted d13")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = Meand13))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()



```

```{r}
d13only_model_structure_x_cohort_re <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){

 d13[i]   ~ dnorm(d13func[i], inv.var13) # where Yi is already log transformed
 d13func[i] <- beta1[struct.cohort[i]] + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i] + beta4[struct.cohort[i]]*VPD.max.scaled[i]

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
beta4[s] ~ dnorm(mu_beta4, inv_beta4)
}




# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)
mu_beta4 ~ dunif(-2, 2)
mu_beta5 ~ dunif(-2, 2)
beta.d131 ~ dnorm(0, 2)
beta.d132 ~ dnorm(0,2)

inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)
inv_beta4   ~ dgamma(0.01, 0.01)
sigma_beta4 <- 1/sqrt(inv_beta4)
inv_beta5   ~ dgamma(0.01, 0.01)
sigma_beta5 <- 1/sqrt(inv_beta5)

# Non-informative Prior for the inverse population variances
inv.var13 ~ dgamma(0.01, 0.01)
sigma_13 <- 1/sqrt(inv.var13)


# Prediction using testing data
for(i in 1:np){

 d13.p[i]   ~ dnorm(d13func.p[i], inv.var13) # where Yi is already log transformed
 d13func.p[i] <- beta1[struct.cohort.p[i]] + beta2[struct.cohort.p[i]]*DI.scaled.p[i] + beta3[struct.cohort.p[i]]*DBH.scaled.p[i] + beta4[struct.cohort.p[i]]*VPD.max.scaled.p[i]

}

}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)

d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)


d13.model.only.by_structure_x_cohort <- jags.model(textConnection(d13only_model_structure_x_cohort_re), 
                    data = list( n=length(train$DI.scaled), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(train$struct.cohort.code), d13 = train$iWUE, VPD.max.scaled= train$jul.VPDmax.scaled, np=length(test$DI.scaled), DI.scaled.p = test$DI.scaled, DBH.scaled.p = test$DBH.scaled, struct.cohort.p = as.numeric(test$struct.cohort.code),  VPD.max.scaled.p= test$jul.VPDmax.scaled), n.chains = 3, n.adapt = 100)

update(d13.model.only.by_structure_x_cohort, 1000); # Burnin for 1000 samples to start, then go higher later


d13.model.only.by_structure_x_cohort <- coda.samples(d13.model.only.by_structure_x_cohort, 
                     variable.names=c("beta1", "beta2","beta3","beta4", "sigma_beta1", "sigma_beta2","sigma_beta3", "sigma_beta4", "d13.p"), 
                    n.chains = 3, n.iter = 20000, thin = 10)

summary(d13.model.only.by_structure_x_cohort)
plot(d13.model.only.by_structure_x_cohort)

gelman.diag(d13.model.only.by_structure_x_cohort)
acfplot(d13.model.only.by_structure_x_cohort)

#Extract the samples for each parameter for a basic exploration of effects

samps       <- d13.model.only.by_structure_x_cohort[[1]]
saveRDS(samps,"outputs/growth_model/wue_reg_struct_x_cohort/samps.rds")
plot(d13.model.only.by_structure_x_cohort)

 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,1:4]
 beta2.samps <- samps[,5:8]
 beta3.samps <- samps[,9:12]
 beta4.samps <- samps[,13:16]
 iWUEpred.samps <- samps[,17:2801]
 #sigma13.samps <- samps[,15]
 #sigma_betas <- samps[,16:18]

 #betad131.samps <- samps[,1]
 #betad132.samps <- samps[,2]


png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_alphas_v3.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta1s_v3.png")
par(mfrow=c(3,2))
hist(beta1.samps[,1], main = "beta2 Past-Savanna")
hist(beta1.samps[,2], main = "beta2 Modern-Savanna")
hist(beta1.samps[,3],  main = "beta2 Past-Forest")
hist(beta1.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta2s_v3.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta3 Past-Savanna")
hist(beta2.samps[,2], main = "beta3 Modern-Savanna")
hist(beta2.samps[,3],  main = "beta3 Past-Forest")
hist(beta2.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(train$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()++xlab("Intercepts for iWUE")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c(unique(train$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Summer Drought")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(train$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Tree DBH")

b4 <- data.frame(beta4.samps)
colnames(b4) <- c(paste0("beta4-",c(unique(train$struct.cohort))))
b4$num <- rownames(b4)
b4.m <- melt(b4, id.vars=c("num"))
b4.mplots <- ggplot(b4.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of July VPD")


library(cowplot)
png(width = 4, height = 8, units = "in", res = 300, "outputs/growth_model/wue_reg_struct_x_cohort/param_marginal_distn_bycohort_struct_v3.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots,b4.mplots, ncol = 1)
dev.off()


# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 VPDprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,VPDprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues

pval113.d <- mean(d13pred.df > d13$Cor.d13C.suess) 


Xp$MeanY <- exp(rowMeans(ypred.df))
Xp$Meand13<- rowMeans(d13pred.df)# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()






#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2, Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted d13")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = Meand13))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()



```


# model growth and response to climate as a function of WUE:

```{r}
wue_model_structure_x_cohort_re_plot_effects <- "model{

# for each the overall population include re for sites:

# Likelihood
for(i in 1:n){

 iWUE[i]   ~ dnorm(gfunc[i], inv.var) # where Yi is already log transformed
 gfunc[i] <- beta1[struct.cohort[i]] + beta2[struct.cohort[i]]*DI.scaled[i] + beta3[struct.cohort[i]]*DBH.scaled[i] + beta4[struct.cohort[i]]*VPD.max.scaled[i] 

}


# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(SF)){
beta1[s] ~ dnorm(mu_beta1, inv_beta1)
beta2[s] ~ dnorm(mu_beta2, inv_beta2)
beta3[s] ~ dnorm(mu_beta3, inv_beta3)
beta4[s] ~ dnorm(mu_beta4, inv_beta4)

#mu_beta2[s] <- gam*exp(v*iWUE.dist[s])
#iWUE.dist[s] ~ dnorm(iWUE.data[s], sigma.WUE[s])

#gam ~ dnorm(0, 0.01)
#v ~ dnorm(0, 0.01)

}


#gam ~ dnorm(0, 0.01)
#v ~ dnorm(0, 0.01)

# use normal hyperpriors for each hyperparamters 
mu_beta1 ~ dunif(-2, 2)
mu_beta2 ~ dunif(-2, 2)
mu_beta3 ~ dunif(-2, 2)
mu_beta4 ~ dunif(-2, 2)
mu_beta5 ~ dunif(-2, 2)


inv_beta1   ~ dgamma(0.01, 0.01)
sigma_beta1 <- 1/sqrt(inv_beta1)
inv_beta2   ~ dgamma(0.01, 0.01)
sigma_beta2 <- 1/sqrt(inv_beta2)
inv_beta3   ~ dgamma(0.01, 0.01)
sigma_beta3 <- 1/sqrt(inv_beta3)
inv_beta4   ~ dgamma(0.01, 0.01)
sigma_beta4 <- 1/sqrt(inv_beta4)
inv_beta5   ~ dgamma(0.01, 0.01)
sigma_beta5 <- 1/sqrt(inv_beta5)

# Non-informative Prior for the inverse population variances
inv.var ~ dgamma(0.01, 0.01)
sigma <- 1/sqrt(inv.var)




}"


# read in the d13 data:


d13 <- read.csv("outputs/stable_isotopes/merged_d13_growth.csv")
d13 <- d13[!is.na(d13$DBH),]
Y.d13 <- log(d13$RWI)
#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass.d13 <- as.numeric( d13$ageclass)
Age.d13 <- as.numeric( d13$Age)
n.d13     <- length(d13$RWI)
DBH.d13 <- d13$DBH
d13$DBH.scaled = as.vector(scale(d13$DBH, center = TRUE, scale = TRUE))
d13$DI.scaled = as.vector(scale(d13$JJA.pdsi, center = TRUE, scale = TRUE))
site.d13 <- d13$site
SpecCode.d13 <- d13$SpecCode
plot.d13 <- unique(d13$site)


iwue.df<- full.ghcn %>% group_by(struct.cohort, struct.cohort.code) %>% summarise(iWUE.dat = median(iWUE, na.rm=TRUE), iwue.sd = sd(iWUE, na.rm = TRUE))

train.df <- merge(iwue.df, train, by = c("struct.cohort", "struct.cohort.code"))
#need to define site level structures:
structure <- data.frame(site = c("AVO","BON","COR",  "ENG",  "GLA",  "GLL1", "GLL2", "GLL3","GLL4", "HIC",  "MOU",  "PLE",  "PVC",  "STC",  "TOW", "UNC" ),
                        structure = c("Forest", "Savanna", "Forest", "Forest", "Savanna", "Forest", "Savanna", "Savanna", "Forest", "Savanna", "Forest","Savanna", "Savanna", "Savanna", "Forest", "Savanna"))



#full.ghcn <- merge(full.ghcn, structure, by = "site")

full.ghcn$struct.cohort <- paste0(full.ghcn$ageclass,"-", full.ghcn$structure)
full.ghcn$struct.cohort.code <- ifelse(full.ghcn$struct.cohort %in% "Past-Forest", 1,
       ifelse(full.ghcn$struct.cohort %in% "Modern-Forest", 2, 
               ifelse(full.ghcn$struct.cohort %in% "Past-Savanna", 3,
                     ifelse(full.ghcn$struct.cohort %in% "Modern-Savanna", 4,"NA" ))))

full.ghcn <- merge(full.ghcn, d13[,c("site", "ID", "year","Cor.d13C.suess", "iWUE")], by = c("site", "ID", "year"), all.x = TRUE)

d13index <- !is.na(full.ghcn$Cor.d13C.suess)
# generate fake data to predict on:
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)


d13.model.only.by_structure_x_cohort <- jags.model(textConnection(growth_wue_model_structure_x_cohort_re), 
                    data = list( n=length(train$DI.scaled), DI.scaled = train$DI.scaled, DBH.scaled = train$DBH.scaled, struct.cohort = as.numeric(train$struct.cohort.code), SF = unique(train$struct.cohort.code), Y = log(train$RWI), VPD.max.scaled= train$jul.VPDmax.scaled, iWUE.data = train.df$iWUE.dat, sigma.WUE = train.df$iwue.sd ), n.chains = 3, n.adapt = 100)

update(growth_wue_model_structure_x_cohort_re, 100); # Burnin for 1000 samples to start, then go higher later


d13.model.only.by_structure_x_cohort <- coda.samples(growth_wue_model_structure_x_cohort_re, 
                     variable.names=c("beta1", "beta2","beta3","beta4", "sigma_beta1", "sigma_beta2","sigma_beta3", "sigma_beta4", "v", "gam", "mu_beta2"), 
                    n.chains = 3, n.iter = 20000, thin = 10)

summary(d13.model.only.by_structure_x_cohort)
plot(d13.model.only.by_structure_x_cohort)

gelman.diag(d13.model.only.by_structure_x_cohort)
acfplot(d13.model.only.by_structure_x_cohort)

#Extract the samples for each parameter for a basic exploration of effects

samps       <- d13.model.only.by_structure_x_cohort[[1]]
saveRDS(samps,"outputs/growth_model/wue_reg_struct_x_cohort/samps.rds")
plot(d13.model.only.by_structure_x_cohort)

 
 #Yp.samps <- samps[,1:660] # one alpha for each of 16 sites
 alpha.samps  <- samps[,1:4]
 beta2.samps <- samps[,5:8]
 beta3.samps <- samps[,9:12]
 beta4.samps <- samps[,13:16]
 sigma.samps <- samps[,17:20]
 #sigma13.samps <- samps[,15]
 #sigma_betas <- samps[,16:18]

 #betad131.samps <- samps[,1]
 #betad132.samps <- samps[,2]


png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_alphas_v3.png")
par(mfrow=c(3,2))
hist(alpha.samps[,1], main = "alpha Past-Savanna")
hist(alpha.samps[,2], main = "alpha Modern-Savanna")
hist(alpha.samps[,3],  main = "alpha Past-Forest")
hist(alpha.samps[,4],  main = "alpha Modern-Forest")
hist(sigma_betas[,1], main = "sigma alpha")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta1s_v3.png")
par(mfrow=c(3,2))
hist(beta1.samps[,1], main = "beta2 Past-Savanna")
hist(beta1.samps[,2], main = "beta2 Modern-Savanna")
hist(beta1.samps[,3],  main = "beta2 Past-Forest")
hist(beta1.samps[,4],  main = "beta2 Modern-Forest")
hist(sigma_betas[,2], main = "sigma beta2")
dev.off()

png("outputs/growth_model/wue_reg_struct_x_cohort/marginal_beta2s_v3.png")
par(mfrow=c(3,2))
hist(beta2.samps[,1], main = "beta3 Past-Savanna")
hist(beta2.samps[,2], main = "beta3 Modern-Savanna")
hist(beta2.samps[,3],  main = "beta3 Past-Forest")
hist(beta2.samps[,4],  main = "beta3 Modern-Forest")
hist(sigma_betas[,3], main = "sigma beta3")
dev.off()


# plot marginal distributions of cohort + structure specific parameters:
a <- data.frame(alpha.samps)
colnames(a) <- c(paste0("alpha-",c(unique(train$struct.cohort))))
a$num <- rownames(a)
a.m <- melt(a, id.vars=c("num"))
alpha.mplots <- ggplot(a.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()++xlab("Intercepts for iWUE")


b2 <- data.frame(beta2.samps)
colnames(b2) <- c(paste0("beta2-",c(unique(train$struct.cohort))))
b2$num <- rownames(b2)
b2.m <- melt(b2, id.vars=c("num"))
b2.mplots <- ggplot(b2.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Summer Drought")


b3 <- data.frame(beta3.samps)
colnames(b3) <- c(paste0("beta3-",c(unique(train$struct.cohort))))
b3$num <- rownames(b3)
b3.m <- melt(b3, id.vars=c("num"))
b3.mplots <- ggplot(b3.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of Tree DBH")

b4 <- data.frame(beta4.samps)
colnames(b4) <- c(paste0("beta4-",c(unique(train$struct.cohort))))
b4$num <- rownames(b4)
b4.m <- melt(b4, id.vars=c("num"))
b4.mplots <- ggplot(b4.m, aes(value, fill = variable))+geom_density(alpha = 0.5)+theme_bw()+xlab("effect of July VPD")


library(cowplot)
png(width = 4, height = 8, units = "in", res = 300, "outputs/growth_model/wue_reg_struct_x_cohort/param_marginal_distn_bycohort_struct_v3.png")
plot_grid(alpha.mplots, b2.mplots, b3.mplots,b4.mplots, ncol = 1)
dev.off()


# Compute the posterior mean for the plug-in predictions  

 beta1.mn  <- colMeans(beta1.samps)
 beta2.mn  <- colMeans(beta2.samps)
 sigma.mn <- mean(sigma.samps)
 alpha1.mn <- colMeans(alpha.samps) 
beta131.mn <- mean(betad131.samps) 
beta132.mn <- mean(betad132.samps) 


# Plot the plug-in Posterior predictive denisty using "fake data"
# want to plaot posteror predictive distributions:
 
# can probe either within the JAGS model or in R after the model runs:
 # specify "x probe" values for DBH + DI:
 #xprobe <- matrix(rep(-2.102618, 3.321394))
 DIprobe <- seq(range(DI.scaled)[1], range(DI.scaled)[2], by = 0.5)
 DBHprobe <- seq(range(DBH.scaled)[1], range(DBH.scaled)[2], by = 0.5)
 
 # something like:
full.probe <- expand.grid(DIprobe, DBHprobe,  struct.cohort= 1:4)
 # use these vals to get ypred
 # compare y pred to y acutal
 # for each value of DI and DBH and site, find the predicted growth based on the model:





 Xp <- full.probe
 np <- length(Xp$Var1)
 ypred <- list()

 d13pred <- list()
 for(j in 1:np){

   # PPD
   #plot(density(Yp.samps[,j]),xlab="Y",main="PPD")

   
   mu <- alpha1.mn[Xp[j,3]] + beta1.mn[Xp[j,3]]*Xp[j,1] + beta2.mn[Xp[j,3]]*Xp[j,2]   # use
   
   ypred[[j]]  <- rnorm(np, mu, sigma.mn)

   # make a prediction of d13 based on MU:
   
   
   
   d13func <- beta131.mn + beta132.mn*ypred[[j]]   # use
   d13pred[[j]]  <- d13func
   # Truth
   #abline(v=Y[j],col=3,lwd=2)

   #legend("topright",c("PPD","Plug-in","Truth"),col=1:3,lty=1,inset=0.05)
}

ypred.df <- do.call(rbind, ypred)
d13pred.df <- do.call(rbind, d13pred)
#ypred.yp.df <- do.call(rbind, ypred.yp)
png("outputs/growth_model/d13_reg_struct_x_cohort/predicted_y_d13.png")
par(mfrow = c(1,2))
plot(density(ypred.df), main = "Ypred, line = Ydata")
abline(v = mean(Y), col = "red")

plot(density(d13pred.df), main = "d13pred, line = d13data")
abline(v= mean(d13$Cor.d13C.suess), col = "red")
dev.off()

# need to calculate pvalues

pval113.d <- mean(d13pred.df > d13$Cor.d13C.suess) 


Xp$MeanY <- exp(rowMeans(ypred.df))
Xp$Meand13<- rowMeans(d13pred.df)# get the means of the posterior to plot the overall effects of 
Xp$struct.cohort <- ifelse(Xp$struct.cohort == 1, "Past-Forest",  
                       ifelse(Xp$struct.cohort == 2, "Modern-Forest",
                               ifelse(Xp$struct.cohort == 3, "Past-Savanna", 
                                       ifelse(Xp$struct.cohort == 4, "Modern-Savanna", NA))))
#DBH + DI on predicted growth

# Todo: unscale Drought and DBH indices

#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,MeanY, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2,MeanY,color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted growth")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = MeanY))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()






#png(height = 4, width = 6, units = "in", res = 200,filename= "/Users/kah/Documents/TreeRings/outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_struct_x_cohort.png")
ggplot(Xp, aes(Var1,Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("Drought Index")+ylab("predicted growth")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var2, Meand13, color = as.factor(struct.cohort)))+geom_point()+xlab("DBH Index")+ylab("predicted d13")+stat_smooth(method = "lm")
#dev.off()

#png(height = 4, width = 6, units = "in", res = 200,"outputs/growth_model/basic_reg_struct_x_cohort_re/Ypred_by_drought_DBH_struct_x_cohort.png")
ggplot(Xp, aes(Var1, Var2, fill = Meand13))+geom_raster()+xlab("Drought Index")+ylab("DBH Index")+scale_fill_distiller(palette = "BrBG", direction = -1)+facet_wrap(~as.factor(struct.cohort))
#dev.off()



```





## Bayesian heirarchical liner regression where alpha and beta coeffiencents are specific to savanna and forest cover:
# this model explores whether stand structure (savanna or forest) has an impact on the slope and intercept response to climate

```{r}


Y <- as.vector(log(full.ghcn$RWI)) 
# create table of savanna and forest

for.df <- data.frame(site = unique(full.ghcn$site), 
           fortype = c("forest", "savanna", "forest" ,"forest", "savanna", "forest", "savanna", "savanna", "forest", "savanna", "savanna", "savanna", "savanna", "savanna", "forest", "savanna"))

full.ghcn <- merge(full.ghcn, for.df, by = "site")
full.ghcn$fornum <- ifelse(full.ghcn$fortype %in% "forest", 1, 2)
# standardise predictor variables to have mean 0 and sd = 1
#DI.scaled = scale(full.ghcn$JJA.pdsi, center= TRUE, scale=TRUE)
#T.scaled = scale(full.ghcn$JUNTmax, center= TRUE, scale=TRUE)
#full.ghcn$DI.scaled = as.vector(scale(full.ghcn$JJA.pdsi, center = TRUE, scale = TRUE))
ggplot(full.ghcn, aes(DI.scaled,log(RWI), color = ageclass))+geom_point(size = 0.2)+geom_smooth(method = "lm")+facet_wrap(~fortype)


png(height= 5, width = 7, units = "in", res = 300, "outputs/two_age_class_logbai_past_mod.png")
ggplot(full.ghcn[full.ghcn$RWI <= 6200, ], aes(JJA.pdsi, log(RWI), color = ageclass))+geom_point(size = 0.02)+geom_smooth(method = "lm")+facet_wrap(~fortype)
dev.off()

#DI <- as.vector( full.ghcn$JJA.pdsi )
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x
full.ghcn$DBH.scaled = as.vector(scale(full.ghcn$DBH.x, center = TRUE, scale = TRUE))
site <- full.ghcn$site
SpecCode <- full.ghcn$SpecCode

summary(lm(Y ~ log(DBH)))

summary(lm(Y ~ log(DBH) + log((pdsi + 10)/20) + log(JunTmax)  ))
summary(lmer(Y ~ DI.scaled+ (DI.scaled|ageclass)))
# population model for the response of each BAI to each year of climate:
population_model_age_class <- "model{

# for each type of stand structure:



# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[fortype[i]], inv.var) # where Yi is already log transformed

# function g()
gfunc[i] <- alpha[fortype[i]]+ beta2[fortype[i]] *DI.scaled[i]    # use Drought index as a scaled variable 
}



# Assume normal priors for betas, but generate a beta + alpha for each ageclass
for(s in 1:length(S)){
alpha[s] ~ dnorm(mu_alpha, inv_alpha)
beta2[s] ~ dnorm(mu_beta, inv_beta)
}

# use normal hyperpriors for each hyperparamters 
mu_alpha ~ dunif(-2, 2)
mu_beta ~ dunif(-2, 2)

inv_alpha   ~ dgamma(0.0001, 0.0001)
sigma_alpha <- 1/sqrt(inv_alpha)
inv_beta   ~ dgamma(0.001, 0.001)
sigma_beta <- 1/sqrt(inv_beta)



# Non-informative Prior for the inverse population variances

#alpha_ref ~ dnorm(0,0.1)
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)

}"

lmer.age <- lmer(Y ~ DI.scaled + (1|ageclass == 1))
ranef(lmer.age)
ggplot(full.ghcn[full.ghcn$RWI < 5500, ], aes(DBH.x, RWI , color = ageclass))+geom_point(size = 0.02)+stat_smooth(method = "lm")
indiv <- lmer(log(RWI) ~ DI.scaled + (DI.scaled|ID), data = full.ghcn)

initsList

# now 
reg.model.by_s <- jags.model(textConnection(population_model_age_class), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, DBH.scaled = full.ghcn$DBH.scaled, fortype = ageclass, S = unique(ageclass)), n.chains = 3, n.adapt = 100)

update(reg.model.by_s, 40000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(reg.model.by_s, 
                     variable.names=c("beta", "beta2","alpha","sigma", "sigma_alpha"), 
                    n.chains = 3, n.iter=20000, thin = 10)

summary(samp)
gelman.diag(samp)
traceplot(samp)
plot(samp)

# quick check to see how params compare to OLS 
#summary(lm(Y ~ full.ghcn$DI.scaled))

# plot mcmc + the parameter distn
plot(samp)
gelman.diag(samp)
acfplot(samp, aspect = 2)


gelman.plot(samp)
# evaluate MCMC convergence:


# save a data frame with beta2 sensitivity and the 
samp.basic.reg.df <- summary(samp)
  
samp.basic.df.sum<- data.frame(mean = samp.df$statistics[2,"Mean"], 
           ci.low = samp.df$quantiles[2,"2.5%"], 
           ci.high = samp.df$quantiles[2,"97.5%"])
  



# lets do the model where stand only affects the slope and not the intercept, perhaps this will help it converge:

population_model_stand <- "model{

# for each type of stand structure:



# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[fortype[i]], inv.var) # where Yi is already log transformed


# function g()
gfunc[i] <- alpha +  beta[fortype[i]]*DI.scaled[i] # use Drought index as a scaled variable 
}

# Assume normal priors for betas, but generate a beta + alpha for each forest type s
for(s in 1:length(S)){

beta[s] ~ dnorm(mu_beta, inv_beta)
}

# use normal hyperpriors for each hyperparamters 
#mu_alpha ~ dnorm(0, 0.1)
mu_beta ~ dnorm(0, 0.1)

#inv_alpha   ~ dgamma(0.001, 0.001)
#sigma_alpha <- 1/sqrt(inv_alpha)
inv_beta   ~ dgamma(0.001, 0.001)
sigma_beta <- 1/sqrt(inv_beta)



# Non-informative Prior for the inverse population variances
inv.var   ~ dgamma(0.001, 0.001)
sigma     <- 1/sqrt(inv.var)
alpha ~ dnorm(0, 0.1)

}"

# now 
reg.model.by_s <- jags.model(textConnection(population_model_stand), 
                    data = list(Y=Y, n=n, DI.scaled = full.ghcn$DI.scaled, fortype =    full.ghcn$fornum, S = unique(full.ghcn$fornum)))

update(reg.model.by_s, 1000); # Burnin for 1000 samples to start, then go higher later

samp <- coda.samples(reg.model.by_s, 
                     variable.names=c("beta","alpha", "sigma"), 
                    n.chains = 4, n.iter=20000)

summary(samp)



```
# this model assumes all trees across all species + sites have the same relationship with summer PDSI + JUNTmax

```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]
Y <- as.vector(log(full.ghcn$RWI)) 

pdsi <- as.vector( full.ghcn$JJA.pdsi)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_pdsi_tmax <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[2]*pdsi[i] + beta[3]*JunTmax[i]
}

# Assume normal priors for betas (because they could be negative or positive)
for(j in 1:3){
beta[j] ~ dnorm(0,0.001)
}



# Prior for the inverse variances
inv.var   ~ dgamma(0.1, 0.1)
sigma     <- 1/sqrt(inv.var)



}"

reg.model.Drought.Tmax <- jags.model(textConnection(model_string_pdsi_tmax), 
                    data = list(Y=Y, n=n, pdsi = pdsi, JunTmax = JunTmax))

update(reg.model.Drought.Tmax, 10000, progress.bar="none"); # Burnin for 10000 samples

samp <- coda.samples(reg.model.Drought.Tmax, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=20000, progress.bar="none")

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  
samps.df.sum<- data.frame(mean = samp.df$statistics[2,"Mean"], 
           ci.low = samp.df$quantiles[2,"2.5%"], 
           ci.high = samp.df$quantiles[2,"97.5%"])
  

ggplot(samps.df.sum, aes("sens",mean))+geom_bar(stat = "identity")+
  geom_errorbar(aes(ymin=ci.low, ymax = ci.high), size = 0.2, width = 0.2)

```


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


# this model assumes all trees across all species + sites have the same relationship with summer PDSI + JUNTmax + DBH, but has a power function as the process model:



```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]


Y <- as.vector(log(full.ghcn$RWI)) 

pdsi <- as.vector( full.ghcn$JJA.pdsi)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_DBH_power <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[1]*log(DBH[i])
}

# Assume normal priors for betas (because they could be negative or positive)
#for(j in 1:2){
beta[1] ~ dnorm(0, 0.002)
beta[2] ~ dnormal(0, 0.002)
#}



# Prior for the inverse variances
inv.var   ~ dgamma(0.01, 0.01)
sigma     <- 1/sqrt(inv.var)


}"

reg.model.dbh.power <- jags.model(textConnection(model_string_DBH_power), 
                    data = list(Y=Y, n=n, DBH = DBH))

update(reg.model.dbh.power, 1000); # Burnin for 1000 samples

samp <- coda.samples(reg.model.dbh.power, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=2000)

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  
samp.dbh.pwr <- do.call(rbind.data.frame, samp)


# compare to the estimates from OLS:

summary(lm(Y ~ log(DBH)))
```
# this model assumes all trees across all species + sites have the same relationship with summer PDSI + JUNTmax + DBH, but has a power function as the process model:

```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]
Y <- as.vector((full.ghcn$RWI)) 

pdsi <- as.vector( full.ghcn$JJA.pdsi)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_pdsi_tmax_DBH_power <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dlnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[2]*log((pdsi[i]+10)/20) + beta[3]*log(JunTmax[i]) + beta[4]*log(DBH[i])
}

# Assume normal priors for betas (because they could be negative or positive)
for(j in 1:4){
beta[j] ~ dlnorm(0,0.001)
}



# Prior for the inverse variances
inv.var   ~ dgamma(0.1, 0.1)
sigma     <- 1/sqrt(inv.var)


}"

reg.model.Drought.Tmax.dbh.power <- jags.model(textConnection(model_string_pdsi_tmax_DBH_power), 
                    data = list(Y=Y, n=n, pdsi = pdsi, JunTmax = JunTmax, DBH = DBH))

update(reg.model.Drought.Tmax.dbh.powe, 10000, progress.bar="none"); # Burnin for 10000 samples

samp <- coda.samples(reg.model.Drought.Tmax.dbh, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=20000, progress.bar="none")

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  

```
# model assumes a power function relationship between growth ~ beta0x(DBH^beta1)x(DBH^2^beta2)x(droghtindex^beta3)x(JunTmax^beta4)
# will need to scale pdsi such that: drought index == ((pdsi+10)/20)

```{r}
summary(full.ghcn)

full.ghcn <- full.ghcn[!is.na(full.ghcn$RWI) & full.ghcn$DBH.x > 0 & !is.na(full.ghcn$DBH.x),]
Y <- as.vector(log(full.ghcn$RWI)) 

pdsi <- as.vector( (full.ghcn$JJA.pdsi + 10)/20)
JunTmax <- as.vector( full.ghcn$JUNTmax)
ageclass <- as.numeric( full.ghcn$ageclass)
Age <- as.numeric( full.ghcn$Age)
n     <- length(full.ghcn$RWI)
DBH <- full.ghcn$DBH.x

model_string_pdsi_tmax_DBH <- "model{

# Likelihood
for(i in 1:n){
# process model
Y[i]   ~ dnorm(gfunc[i], inv.var)

# function g()
gfunc[i] <- beta[1] +  beta[2]*pdsi[i] + beta[3]*JunTmax[i] + beta[4]*DBH[i]
}

# Assume normal priors for betas (because they could be negative or positive)
for(j in 1:4){
beta[j] ~ dnorm(0,0.001)
}



# Prior for the inverse variances
inv.var   ~ dgamma(0.1, 0.1)
sigma     <- 1/sqrt(inv.var)



}"

reg.model.Drought.Tmax.dbh <- jags.model(textConnection(model_string_pdsi_tmax_DBH), 
                    data = list(Y=Y, n=n, pdsi = pdsi, JunTmax = JunTmax, DBH = DBH))

update(reg.model.Drought.Tmax.dbh, 10000, progress.bar="none"); # Burnin for 10000 samples

samp <- coda.samples(reg.model.Drought.Tmax.dbh, 
                     variable.names=c("beta","sigma"), 
                    n.chains = 3, n.iter=20000, progress.bar="none")

summary(samp)


# plot mcmc + the parameter distn
plot(samp)

# save a data frame with beta2 sensitivity and the 
samp.df <- summary(samp)
  

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
